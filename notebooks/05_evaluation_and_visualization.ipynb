{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Visualization of Seismic Interpolation Model\n",
    "\n",
    "This notebook demonstrates how to evaluate and visualize the results of the trained seismic interpolation model. We'll go through the following steps:\n",
    "\n",
    "1. Load the trained model\n",
    "2. Load test data and perform inference\n",
    "3. Compute comprehensive evaluation metrics\n",
    "4. Create visualizations for qualitative assessment\n",
    "5. Analyze model performance under different masking scenarios\n",
    "6. Generate publication-quality figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "\n",
    "# Add the project root to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.models.transformer import StorSeismicBERTModel\n",
    "from src.preprocessing.dataset import TransformerSeismicDataset\n",
    "from src.evaluation.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, signal_to_noise_ratio,\n",
    "    correlation_coefficient, coherence_measure, frequency_domain_error,\n",
    "    amplitude_ratio, evaluate_model\n",
    ")\n",
    "from src.utils.logging_utils import setup_logging\n",
    "from src.utils.plot_utils import (\n",
    "    plot_trace_comparison, plot_gather_comparison, plot_seismic_trace,\n",
    "    plot_frequency_comparison, plot_scatter_true_vs_pred, plot_metrics_comparison\n",
    ")\n",
    "\n",
    "# Set up logging\n",
    "logger = setup_logging(level='INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model\n",
    "\n",
    "Load the transformer model that was trained in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths\n",
    "data_dir = \"../data/synthetic/processed/datasets\"\n",
    "models_dir = \"../experiments/models\"\n",
    "results_dir = \"../experiments/results\"\n",
    "figures_dir = \"../papers/figures\"\n",
    "\n",
    "# Ensure directories exist\n",
    "Path(results_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(figures_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load model\n",
    "experiment_name = \"seismic_interpolation_transformer\"\n",
    "model_path = Path(models_dir) / f\"{experiment_name}_final_model.pt\"\n",
    "\n",
    "# Check if model exists\n",
    "if not model_path.exists():\n",
    "    print(f\"Model not found at {model_path}. Please run the training notebook first.\")\n",
    "else:\n",
    "    # Load model checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model_config = checkpoint['model_config']\n",
    "    dataset_params = checkpoint['dataset_params']\n",
    "    \n",
    "    # Print model config\n",
    "    print(\"Model Configuration:\")\n",
    "    for key, value in model_config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "        \n",
    "    # Initialize model with the same configuration\n",
    "    model = StorSeismicBERTModel(\n",
    "        max_channels=model_config['max_channels'],\n",
    "        time_steps=model_config['time_steps'],\n",
    "        d_model=model_config['d_model'],\n",
    "        nhead=model_config['nhead'],\n",
    "        num_layers=model_config['num_layers'],\n",
    "        dim_feedforward=model_config['dim_feedforward'],\n",
    "        dropout=model_config['dropout']\n",
    "    )\n",
    "    \n",
    "    # Load state dict\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Loaded model from {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data\n",
    "\n",
    "Load the test data for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load windowed data\n",
    "geophone_windows = np.load(Path(data_dir) / \"geophone_windows.npy\")\n",
    "das_windows = np.load(Path(data_dir) / \"das_windows.npy\")\n",
    "\n",
    "# Load test indices\n",
    "test_indices = np.load(Path(data_dir) / \"test_indices.npy\")\n",
    "\n",
    "# Get test data\n",
    "test_geo = geophone_windows[test_indices]\n",
    "test_das = das_windows[test_indices]\n",
    "\n",
    "print(f\"Loaded {len(test_indices)} test samples\")\n",
    "print(f\"Test geophone data shape: {test_geo.shape}\")\n",
    "print(f\"Test DAS data shape: {test_das.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create test datasets with different mask ratios\n",
    "mask_patterns = ['random', 'regular', 'block']\n",
    "mask_ratios = [0.1, 0.3, 0.5, 0.7]  # From 10% to 70% channels masked\n",
    "\n",
    "# Create test datasets\n",
    "test_datasets = {}\n",
    "for pattern in mask_patterns:\n",
    "    pattern_datasets = {}\n",
    "    for ratio in mask_ratios:\n",
    "        dataset = TransformerSeismicDataset(\n",
    "            test_geo, test_das, \n",
    "            mask_ratio=ratio, \n",
    "            mask_pattern=pattern, \n",
    "            positional_encoding=True\n",
    "        )\n",
    "        pattern_datasets[ratio] = dataset\n",
    "    test_datasets[pattern] = pattern_datasets\n",
    "\n",
    "# Create test dataloader for the standard case (random, 30%)\n",
    "batch_size = 32\n",
    "standard_test_dataset = test_datasets['random'][0.3]\n",
    "test_loader = DataLoader(standard_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Inference on Test Data\n",
    "\n",
    "Run inference on the test data to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run inference on one batch\n",
    "def run_inference(model, batch, device):\n",
    "    \"\"\"Run inference on a batch of data.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Unpack batch\n",
    "        input_data, attention_mask, positions, target = batch\n",
    "        input_data = input_data.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        positions = positions.to(device) if positions is not None else None\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_data, attention_mask=attention_mask, position_ids=positions)\n",
    "        \n",
    "        # Extract geophone predictions\n",
    "        n_das_channels = outputs.shape[1] - target.shape[1]\n",
    "        predicted_geophone = outputs[:, n_das_channels:, :]\n",
    "        \n",
    "        # Get mask for geophone channels (masked channels have attention_mask=0)\n",
    "        geo_mask = ~attention_mask[:, n_das_channels:].bool()\n",
    "        \n",
    "        return {\n",
    "            'input_data': input_data.cpu().numpy(),\n",
    "            'attention_mask': attention_mask.cpu().numpy(),\n",
    "            'target': target.cpu().numpy(),\n",
    "            'predictions': predicted_geophone.cpu().numpy(),\n",
    "            'geo_mask': geo_mask.cpu().numpy(),\n",
    "            'n_das_channels': n_das_channels\n",
    "        }\n",
    "\n",
    "# Get a test batch\n",
    "test_batch = next(iter(test_loader))\n",
    "\n",
    "# Run inference\n",
    "results = run_inference(model, test_batch, device)\n",
    "\n",
    "print(f\"Ran inference on batch of {results['predictions'].shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Evaluation Metrics\n",
    "\n",
    "Compute comprehensive metrics to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compute metrics for the first sample\n",
    "sample_idx = 0\n",
    "\n",
    "# Get masked channels for this sample\n",
    "geo_mask = results['geo_mask'][sample_idx]\n",
    "target = results['target'][sample_idx]\n",
    "predictions = results['predictions'][sample_idx]\n",
    "\n",
    "# Compute metrics for masked channels only\n",
    "masked_indices = np.where(geo_mask)\n",
    "masked_targets = target[masked_indices]\n",
    "masked_predictions = predictions[masked_indices]\n",
    "\n",
    "# Flatten the arrays (each masked channel becomes a row)\n",
    "masked_targets_flat = masked_targets.reshape(-1, masked_targets.shape[-1])\n",
    "masked_predictions_flat = masked_predictions.reshape(-1, masked_predictions.shape[-1])\n",
    "\n",
    "# Compute metrics\n",
    "mse = mean_squared_error(masked_targets_flat, masked_predictions_flat)\n",
    "mae = mean_absolute_error(masked_targets_flat, masked_predictions_flat)\n",
    "snr = signal_to_noise_ratio(masked_targets_flat, masked_predictions_flat)\n",
    "corr = correlation_coefficient(masked_targets_flat.flatten(), masked_predictions_flat.flatten())\n",
    "amp_ratio = amplitude_ratio(masked_targets_flat, masked_predictions_flat)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Metrics for Sample {sample_idx}:\")\n",
    "print(f\"  Mean Squared Error: {mse:.6f}\")\n",
    "print(f\"  Mean Absolute Error: {mae:.6f}\")\n",
    "print(f\"  Signal-to-Noise Ratio: {snr:.2f} dB\")\n",
    "print(f\"  Correlation Coefficient: {corr:.4f}\")\n",
    "print(f\"  Amplitude Ratio: {amp_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compute metrics on the full test set\n",
    "print(\"Computing metrics on full test set...\")\n",
    "full_metrics = evaluate_model(model, test_loader, device)\n",
    "\n",
    "print(\"Full Test Set Metrics:\")\n",
    "for metric, value in full_metrics.items():\n",
    "    print(f\"  {metric}: {value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Predictions\n",
    "\n",
    "Create visualizations to qualitatively assess the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize predictions for the first sample\n",
    "sample_idx = 0\n",
    "\n",
    "# Get sample data\n",
    "input_data = results['input_data'][sample_idx]\n",
    "target = results['target'][sample_idx]\n",
    "predictions = results['predictions'][sample_idx]\n",
    "geo_mask = results['geo_mask'][sample_idx]\n",
    "n_das_channels = results['n_das_channels']\n",
    "\n",
    "# Extract DAS data\n",
    "das_data = input_data[:n_das_channels]\n",
    "\n",
    "# Create masked geophone data (with zeros for masked channels)\n",
    "masked_geophone = input_data[n_das_channels:].copy()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Plot DAS data\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.imshow(das_data, aspect='auto', cmap='seismic')\n",
    "plt.title(\"DAS Data (Input)\")\n",
    "plt.ylabel(\"Channel\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Plot masked geophone data\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.imshow(masked_geophone, aspect='auto', cmap='seismic')\n",
    "plt.title(\"Masked Geophone Data (Input)\")\n",
    "plt.ylabel(\"Channel\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Plot predicted geophone data\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.imshow(predictions, aspect='auto', cmap='seismic')\n",
    "plt.title(\"Predicted Geophone Data (Output)\")\n",
    "plt.ylabel(\"Channel\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Plot true geophone data\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.imshow(target, aspect='auto', cmap='seismic')\n",
    "plt.title(\"True Geophone Data (Ground Truth)\")\n",
    "plt.xlabel(\"Time Sample\")\n",
    "plt.ylabel(\"Channel\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(figures_dir) / \"full_prediction_visualization.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize individual traces for comparison\n",
    "# Choose a masked channel\n",
    "masked_channel_idx = np.where(geo_mask)[0][0]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(target[masked_channel_idx], 'b-', label='True')\n",
    "plt.plot(predictions[masked_channel_idx], 'r-', label='Predicted')\n",
    "plt.title(f\"True vs Predicted - Channel {masked_channel_idx} (Masked)\")\n",
    "plt.xlabel(\"Time Sample\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Add metrics text\n",
    "mse_val = mean_squared_error(target[masked_channel_idx], predictions[masked_channel_idx])\n",
    "snr_val = signal_to_noise_ratio(target[masked_channel_idx], predictions[masked_channel_idx])\n",
    "corr_val = correlation_coefficient(target[masked_channel_idx], predictions[masked_channel_idx])\n",
    "\n",
    "metrics_text = f'MSE: {mse_val:.6f}\\nSNR: {snr_val:.2f} dB\\nCorr: {corr_val:.4f}'\n",
    "plt.text(0.02, 0.98, metrics_text, transform=plt.gca().transAxes,\n",
    "         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(figures_dir) / \"trace_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot frequency comparison for a masked channel\n",
    "f, cxy = plot_frequency_comparison(\n",
    "    target[masked_channel_idx], \n",
    "    predictions[masked_channel_idx],\n",
    "    fs=100,  # Assuming 100 Hz sampling rate\n",
    "    title=f\"Frequency Domain Comparison - Channel {masked_channel_idx}\",\n",
    "    save_path=Path(figures_dir) / \"frequency_comparison.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Performance with Different Masking Patterns and Ratios\n",
    "\n",
    "Evaluate how the model performs with different masking patterns and ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to evaluate on a dataset\n",
    "def evaluate_dataset(model, dataset, device, num_samples=50):\n",
    "    \"\"\"Evaluate model on a dataset.\"\"\"\n",
    "    model.eval()\n",
    "    metrics = {\n",
    "        'mse': [],\n",
    "        'snr': [],\n",
    "        'corr': []\n",
    "    }\n",
    "    \n",
    "    # Create a small dataloader\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sample_count = 0\n",
    "        for batch in loader:\n",
    "            results = run_inference(model, batch, device)\n",
    "            \n",
    "            for i in range(len(results['predictions'])):\n",
    "                # Get masked channels for this sample\n",
    "                geo_mask = results['geo_mask'][i]\n",
    "                target = results['target'][i]\n",
    "                predictions = results['predictions'][i]\n",
    "                \n",
    "                # Compute metrics for masked channels only\n",
    "                masked_indices = np.where(geo_mask)\n",
    "                if len(masked_indices[0]) > 0:  # Make sure there are masked channels\n",
    "                    masked_targets = target[masked_indices]\n",
    "                    masked_predictions = predictions[masked_indices]\n",
    "                    \n",
    "                    # Compute metrics\n",
    "                    mse = mean_squared_error(masked_targets, masked_predictions)\n",
    "                    snr = signal_to_noise_ratio(masked_targets, masked_predictions)\n",
    "                    corr = correlation_coefficient(masked_targets.flatten(), masked_predictions.flatten())\n",
    "                    \n",
    "                    metrics['mse'].append(mse)\n",
    "                    metrics['snr'].append(snr)\n",
    "                    metrics['corr'].append(corr)\n",
    "                    \n",
    "                sample_count += 1\n",
    "                if sample_count >= num_samples:\n",
    "                    break\n",
    "            \n",
    "            if sample_count >= num_samples:\n",
    "                break\n",
    "    \n",
    "    # Compute average metrics\n",
    "    avg_metrics = {}\n",
    "    for key, values in metrics.items():\n",
    "        avg_metrics[key] = np.mean(values)\n",
    "    \n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate on different masking patterns and ratios\n",
    "pattern_metrics = {}\n",
    "\n",
    "for pattern in mask_patterns:\n",
    "    ratio_metrics = {}\n",
    "    for ratio in mask_ratios:\n",
    "        print(f\"Evaluating {pattern} pattern with {ratio*100:.0f}% masking...\")\n",
    "        dataset = test_datasets[pattern][ratio]\n",
    "        metrics = evaluate_dataset(model, dataset, device, num_samples=20)  # Using a small number for speed\n",
    "        ratio_metrics[ratio] = metrics\n",
    "    pattern_metrics[pattern] = ratio_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot metrics vs mask ratio for each pattern\n",
    "metrics_to_plot = ['mse', 'snr', 'corr']\n",
    "titles = {\n",
    "    'mse': 'Mean Squared Error',\n",
    "    'snr': 'Signal-to-Noise Ratio (dB)',\n",
    "    'corr': 'Correlation Coefficient'\n",
    "}\n",
    "\n",
    "for metric_name in metrics_to_plot:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for pattern in mask_patterns:\n",
    "        ratios = list(pattern_metrics[pattern].keys())\n",
    "        values = [pattern_metrics[pattern][ratio][metric_name] for ratio in ratios]\n",
    "        plt.plot([r*100 for r in ratios], values, 'o-', label=pattern.capitalize())\n",
    "    \n",
    "    plt.title(f\"{titles[metric_name]} vs Mask Ratio\")\n",
    "    plt.xlabel(\"Mask Ratio (%)\")\n",
    "    plt.ylabel(titles[metric_name])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(figures_dir) / f\"{metric_name}_vs_mask_ratio.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Masking Patterns\n",
    "\n",
    "Create visualizations to show how different masking patterns affect the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a function to visualize masking patterns\n",
    "def visualize_masking_pattern(pattern, ratio):\n",
    "    \"\"\"Visualize a masking pattern.\"\"\"\n",
    "    # Create a dataset with the specific pattern and ratio\n",
    "    dataset = TransformerSeismicDataset(\n",
    "        test_geo[:1], test_das[:1],  # Just use the first sample\n",
    "        mask_ratio=ratio,\n",
    "        mask_pattern=pattern,\n",
    "        positional_encoding=True\n",
    "    )\n",
    "    \n",
    "    # Get the sample\n",
    "    input_data, attention_mask, positions, target = dataset[0]\n",
    "    \n",
    "    # Get the mask\n",
    "    n_das_channels = input_data.shape[0] - target.shape[0]\n",
    "    geo_mask = ~attention_mask[n_das_channels:].bool().numpy()\n",
    "    \n",
    "    # Create a visualization of the mask\n",
    "    mask_viz = np.zeros((1, geo_mask.shape[0]))\n",
    "    mask_viz[0, geo_mask] = 1\n",
    "    \n",
    "    return mask_viz\n",
    "\n",
    "# Visualize different mask patterns with 30% ratio\n",
    "ratio = 0.3\n",
    "mask_visualizations = {}\n",
    "\n",
    "for pattern in mask_patterns:\n",
    "    mask_viz = visualize_masking_pattern(pattern, ratio)\n",
    "    mask_visualizations[pattern] = mask_viz\n",
    "\n",
    "# Plot masks\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, pattern in enumerate(mask_patterns):\n",
    "    plt.subplot(len(mask_patterns), 1, i+1)\n",
    "    plt.imshow(mask_visualizations[pattern], aspect='auto', cmap='binary')\n",
    "    plt.title(f\"{pattern.capitalize()} Masking Pattern ({ratio*100:.0f}% masked)\")\n",
    "    plt.ylabel(\"Mask\")\n",
    "    if i == len(mask_patterns) - 1:\n",
    "        plt.xlabel(\"Channel Index\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(figures_dir) / \"masking_patterns.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Publication-Quality Figures\n",
    "\n",
    "Create high-quality figures for publication, showing the model's performance on representative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a full figure showing the entire pipeline\n",
    "def create_pipeline_figure(sample_idx=0):\n",
    "    \"\"\"Create a figure showing the entire interpolation pipeline.\"\"\"\n",
    "    # Get the sample data\n",
    "    input_data = results['input_data'][sample_idx]\n",
    "    target = results['target'][sample_idx]\n",
    "    predictions = results['predictions'][sample_idx]\n",
    "    geo_mask = results['geo_mask'][sample_idx]\n",
    "    n_das_channels = results['n_das_channels']\n",
    "    \n",
    "    # Extract DAS data\n",
    "    das_data = input_data[:n_das_channels]\n",
    "    \n",
    "    # Create masked geophone data (with zeros for masked channels)\n",
    "    masked_geophone = input_data[n_das_channels:].copy()\n",
    "    \n",
    "    # Create a figure showing the entire pipeline\n",
    "    fig = plt.figure(figsize=(18, 14))\n",
    "    gs = fig.add_gridspec(5, 2, height_ratios=[1, 1, 1, 1, 0.5])\n",
    "    \n",
    "    # Plot DAS data\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    im1 = ax1.imshow(das_data, aspect='auto', cmap='seismic')\n",
    "    ax1.set_title(\"DAS Data (Input)\", fontsize=14)\n",
    "    ax1.set_ylabel(\"DAS Channel\", fontsize=12)\n",
    "    fig.colorbar(im1, ax=ax1)\n",
    "    \n",
    "    # Plot masked geophone data\n",
    "    ax2 = fig.add_subplot(gs[1, :])\n",
    "    im2 = ax2.imshow(masked_geophone, aspect='auto', cmap='seismic')\n",
    "    ax2.set_title(\"Masked Geophone Data (Input)\", fontsize=14)\n",
    "    ax2.set_ylabel(\"Geophone Channel\", fontsize=12)\n",
    "    fig.colorbar(im2, ax=ax2)\n",
    "    \n",
    "    # Mark masked channels\n",
    "    for i, masked in enumerate(geo_mask):\n",
    "        if masked:\n",
    "            ax2.axhline(i, color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Plot predicted geophone data\n",
    "    ax3 = fig.add_subplot(gs[2, :])\n",
    "    im3 = ax3.imshow(predictions, aspect='auto', cmap='seismic')\n",
    "    ax3.set_title(\"Predicted Geophone Data (Model Output)\", fontsize=14)\n",
    "    ax3.set_ylabel(\"Geophone Channel\", fontsize=12)\n",
    "    fig.colorbar(im3, ax=ax3)\n",
    "    \n",
    "    # Plot true geophone data\n",
    "    ax4 = fig.add_subplot(gs[3, :])\n",
    "    im4 = ax4.imshow(target, aspect='auto', cmap='seismic')\n",
    "    ax4.set_title(\"True Geophone Data (Ground Truth)\", fontsize=14)\n",
    "    ax4.set_xlabel(\"Time Sample\", fontsize=12)\n",
    "    ax4.set_ylabel(\"Geophone Channel\", fontsize=12)\n",
    "    fig.colorbar(im4, ax=ax4)\n",
    "    \n",
    "    # Plot comparison of a masked channel\n",
    "    masked_channel_idx = np.where(geo_mask)[0][0]\n",
    "    \n",
    "    ax5 = fig.add_subplot(gs[4, 0])\n",
    "    ax5.plot(target[masked_channel_idx], 'b-', label='True')\n",
    "    ax5.plot(predictions[masked_channel_idx], 'r-', label='Predicted')\n",
    "    ax5.set_title(f\"Channel {masked_channel_idx} Comparison\", fontsize=14)\n",
    "    ax5.set_xlabel(\"Time Sample\", fontsize=12)\n",
    "    ax5.set_ylabel(\"Amplitude\", fontsize=12)\n",
    "    ax5.legend(fontsize=10)\n",
    "    ax5.grid(True)\n",
    "    \n",
    "    # Add metrics for this channel\n",
    "    mse_val = mean_squared_error(target[masked_channel_idx], predictions[masked_channel_idx])\n",
    "    snr_val = signal_to_noise_ratio(target[masked_channel_idx], predictions[masked_channel_idx])\n",
    "    corr_val = correlation_coefficient(target[masked_channel_idx], predictions[masked_channel_idx])\n",
    "    \n",
    "    # Plot frequency comparison\n",
    "    ax6 = fig.add_subplot(gs[4, 1])\n",
    "    fs = 100  # Assuming 100 Hz sampling rate\n",
    "    f, psd_true = signal.welch(target[masked_channel_idx], fs, nperseg=256)\n",
    "    f, psd_pred = signal.welch(predictions[masked_channel_idx], fs, nperseg=256)\n",
    "    ax6.semilogy(f, psd_true, 'b-', label='True')\n",
    "    ax6.semilogy(f, psd_pred, 'r-', label='Predicted')\n",
    "    ax6.set_title(f\"Frequency Content - Channel {masked_channel_idx}\", fontsize=14)\n",
    "    ax6.set_xlabel(\"Frequency (Hz)\", fontsize=12)\n",
    "    ax6.set_ylabel(\"PSD\", fontsize=12)\n",
    "    ax6.legend(fontsize=10)\n",
    "    ax6.grid(True)\n",
    "    \n",
    "    # Add overall metrics text\n",
    "    plt.figtext(0.5, 0.01, \n",
    "               f\"MSE: {mse_val:.6f} | SNR: {snr_val:.2f} dB | Correlation: {corr_val:.4f}\", \n",
    "               ha=\"center\", fontsize=12, \n",
    "               bbox={\"facecolor\":\"white\", \"alpha\":0.5, \"pad\":5})\n",
    "    \n",
    "    plt.suptitle(\"Seismic Interpolation with Transformer Model\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and save the figure\n",
    "pipeline_fig = create_pipeline_figure(sample_idx=0)\n",
    "pipeline_fig.savefig(Path(figures_dir) / \"complete_pipeline.png\", dpi=300, bbox_inches='tight')\n",
    "pipeline_fig.savefig(Path(figures_dir) / \"complete_pipeline.pdf\", format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a comparison figure for different masking patterns\n",
    "def create_masking_comparison_figure():\n",
    "    \"\"\"Create a figure comparing model performance with different masking patterns.\"\"\"\n",
    "    # Set up the figure\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "    \n",
    "    # For each pattern and a fixed ratio (30%)\n",
    "    ratio = 0.3\n",
    "    for i, pattern in enumerate(mask_patterns):\n",
    "        # Create a dataset with this pattern\n",
    "        dataset = TransformerSeismicDataset(\n",
    "            test_geo[:1], test_das[:1],  # Just use the first sample\n",
    "            mask_ratio=ratio,\n",
    "            mask_pattern=pattern,\n",
    "            positional_encoding=True\n",
    "        )\n",
    "        \n",
    "        # Get batch\n",
    "        batch = [t.unsqueeze(0) for t in dataset[0]]  # Add batch dimension\n",
    "        \n",
    "        # Run inference\n",
    "        results = run_inference(model, batch, device)\n",
    "        \n",
    "        # Plot masked geophone\n",
    "        masked_geophone = results['input_data'][0, results['n_das_channels']:]\n",
    "        ax = axes[i, 0]\n",
    "        im = ax.imshow(masked_geophone, aspect='auto', cmap='seismic')\n",
    "        ax.set_title(f\"{pattern.capitalize()} - Masked Input\")\n",
    "        if i == 2:\n",
    "            ax.set_xlabel(\"Time Sample\")\n",
    "        ax.set_ylabel(\"Channel\")\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        \n",
    "        # Plot predictions\n",
    "        predictions = results['predictions'][0]\n",
    "        ax = axes[i, 1]\n",
    "        im = ax.imshow(predictions, aspect='auto', cmap='seismic')\n",
    "        ax.set_title(f\"{pattern.capitalize()} - Predictions\")\n",
    "        if i == 2:\n",
    "            ax.set_xlabel(\"Time Sample\")\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        \n",
    "        # Plot true data\n",
    "        target = results['target'][0]\n",
    "        ax = axes[i, 2]\n",
    "        im = ax.imshow(target, aspect='auto', cmap='seismic')\n",
    "        ax.set_title(f\"{pattern.capitalize()} - Ground Truth\")\n",
    "        if i == 2:\n",
    "            ax.set_xlabel(\"Time Sample\")\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        \n",
    "        # Compute metrics\n",
    "        geo_mask = results['geo_mask'][0]\n",
    "        masked_indices = np.where(geo_mask)\n",
    "        masked_targets = target[masked_indices]\n",
    "        masked_predictions = predictions[masked_indices]\n",
    "        \n",
    "        mse = mean_squared_error(masked_targets, masked_predictions)\n",
    "        snr = signal_to_noise_ratio(masked_targets, masked_predictions)\n",
    "        corr = correlation_coefficient(masked_targets.flatten(), masked_predictions.flatten())\n",
    "        \n",
    "        # Add metrics as text\n",
    "        metrics_text = f\"MSE: {mse:.6f}\\nSNR: {snr:.2f} dB\\nCorr: {corr:.4f}\"\n",
    "        axes[i, 1].text(0.5, 0.05, metrics_text, transform=axes[i, 1].transAxes,\n",
    "                      ha='center', va='bottom',\n",
    "                      bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle(f\"Comparison of Masking Patterns ({ratio*100:.0f}% masked)\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and save the figure\n",
    "masking_fig = create_masking_comparison_figure()\n",
    "masking_fig.savefig(Path(figures_dir) / \"masking_patterns_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "masking_fig.savefig(Path(figures_dir) / \"masking_patterns_comparison.pdf\", format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a summary figure for the paper\n",
    "def create_metrics_summary_figure():\n",
    "    \"\"\"Create a summary figure of metrics for the paper.\"\"\"\n",
    "    # Create a dataframe with pattern, ratio, and metrics\n",
    "    data = []\n",
    "    for pattern in mask_patterns:\n",
    "        for ratio in mask_ratios:\n",
    "            metrics = pattern_metrics[pattern][ratio]\n",
    "            data.append({\n",
    "                'Pattern': pattern.capitalize(),\n",
    "                'Mask Ratio': ratio * 100,  # Convert to percentage\n",
    "                'MSE': metrics['mse'],\n",
    "                'SNR (dB)': metrics['snr'],\n",
    "                'Correlation': metrics['corr']\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create a figure with three subplots (one for each metric)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Plot MSE\n",
    "    sns.barplot(x='Pattern', y='MSE', hue='Mask Ratio', data=df, ax=axes[0])\n",
    "    axes[0].set_title('Mean Squared Error')\n",
    "    axes[0].set_xlabel('Masking Pattern')\n",
    "    axes[0].set_ylabel('MSE')\n",
    "    \n",
    "    # Plot SNR\n",
    "    sns.barplot(x='Pattern', y='SNR (dB)', hue='Mask Ratio', data=df, ax=axes[1])\n",
    "    axes[1].set_title('Signal-to-Noise Ratio')\n",
    "    axes[1].set_xlabel('Masking Pattern')\n",
    "    axes[1].set_ylabel('SNR (dB)')\n",
    "    \n",
    "    # Plot Correlation\n",
    "    sns.barplot(x='Pattern', y='Correlation', hue='Mask Ratio', data=df, ax=axes[2])\n",
    "    axes[2].set_title('Correlation Coefficient')\n",
    "    axes[2].set_xlabel('Masking Pattern')\n",
    "    axes[2].set_ylabel('Correlation')\n",
    "    \n",
    "    # Adjust legend\n",
    "    for ax in axes:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles, [f\"{r}%\" for r in sorted([int(label) for label in labels])], title='Mask Ratio')\n",
    "    \n",
    "    plt.suptitle('Performance Metrics for Different Masking Patterns and Ratios', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and save the figure\n",
    "metrics_fig = create_metrics_summary_figure()\n",
    "metrics_fig.savefig(Path(figures_dir) / \"metrics_summary.png\", dpi=300, bbox_inches='tight')\n",
    "metrics_fig.savefig(Path(figures_dir) / \"metrics_summary.pdf\", format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Evaluation Results\n",
    "\n",
    "Save the evaluation results to a CSV file for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a dataframe with all evaluation results\n",
    "evaluation_data = []\n",
    "for pattern in mask_patterns:\n",
    "    for ratio in mask_ratios:\n",
    "        metrics = pattern_metrics[pattern][ratio]\n",
    "        evaluation_data.append({\n",
    "            'Pattern': pattern,\n",
    "            'Mask Ratio': ratio,\n",
    "            'MSE': metrics['mse'],\n",
    "            'SNR': metrics['snr'],\n",
    "            'Correlation': metrics['corr']\n",
    "        })\n",
    "\n",
    "evaluation_df = pd.DataFrame(evaluation_data)\n",
    "\n",
    "# Save to CSV\n",
    "evaluation_df.to_csv(Path(results_dir) / \"evaluation_results.csv\", index=False)\n",
    "print(f\"Saved evaluation results to {Path(results_dir) / 'evaluation_results.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Loaded the trained transformer model for seismic interpolation\n",
    "2. Run inference on test data and evaluated the model's performance\n",
    "3. Analyzed the impact of different masking patterns and ratios\n",
    "4. Created publication-quality figures to visualize the results\n",
    "5. Demonstrated the effectiveness of the transformer model for interpolating missing geophone data using DAS constraints\n",
    "\n",
    "The evaluation results show that the model performs well across different masking patterns and ratios, with the performance naturally declining as the mask ratio increases. These findings highlight the potential of this approach for practical applications in seismic data processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}