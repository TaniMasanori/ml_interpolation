{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAS Conversion: From Particle Velocity to Strain Rate\n",
    "\n",
    "This notebook demonstrates how to convert SPECFEM3D particle velocity outputs to Distributed Acoustic Sensing (DAS) strain-rate responses. We'll go through the following steps:\n",
    "\n",
    "1. Load synthetic seismic data generated by SPECFEM3D\n",
    "2. Apply the DAS conversion algorithm to simulate DAS strain-rate measurements\n",
    "3. Visualize and compare geophone and DAS data\n",
    "4. Save the processed DAS data for use in the interpolation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.simulation.das_converter import DASConverter\n",
    "from src.utils.logging_utils import setup_logging\n",
    "from src.utils.plot_utils import plot_seismic_trace, plot_seismic_gather, plot_multiple_traces\n",
    "\n",
    "# Set up logging\n",
    "logger = setup_logging(level='INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Define paths and parameters for the DAS conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Paths\n",
    "raw_data_dir = \"../data/synthetic/raw/simulation1\"  # Raw simulation outputs\n",
    "processed_geo_dir = \"../data/synthetic/processed/simulation1\"  # Processed geophone data\n",
    "processed_das_dir = \"../data/synthetic/processed/simulation1/das\"  # Directory for DAS data\n",
    "\n",
    "# Ensure output directory exists\n",
    "Path(processed_das_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# DAS parameters\n",
    "gauge_length = 10.0  # Gauge length in meters\n",
    "channel_spacing = 10.0  # Spacing between DAS channels in meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Synthetic Geophone Data\n",
    "\n",
    "Load the synthetic seismic data generated by SPECFEM3D. We'll use the particle velocity data as the basis for DAS conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if processed data exists\n",
    "if Path(processed_geo_dir).exists():\n",
    "    # Load processed data\n",
    "    times = np.load(Path(processed_geo_dir) / \"times.npy\")\n",
    "    data_x = np.load(Path(processed_geo_dir) / \"data_x.npy\")\n",
    "    data_y = np.load(Path(processed_geo_dir) / \"data_y.npy\")\n",
    "    data_z = np.load(Path(processed_geo_dir) / \"data_z.npy\")\n",
    "    station_df = pd.read_csv(Path(processed_geo_dir) / \"stations.csv\")\n",
    "    \n",
    "    print(f\"Loaded {data_x.shape[0]} X-component seismograms, each with {data_x.shape[1]} time steps.\")\n",
    "    print(f\"Loaded {data_y.shape[0]} Y-component seismograms, each with {data_y.shape[1]} time steps.\")\n",
    "    print(f\"Loaded {data_z.shape[0]} Z-component seismograms, each with {data_z.shape[1]} time steps.\")\n",
    "else:\n",
    "    print(f\"Processed data not found in {processed_geo_dir}. Run the simulation notebook first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Particle Velocity to DAS Strain Rate\n",
    "\n",
    "Now we'll convert the particle velocity data to DAS strain-rate measurements using the DASConverter class. For this example, we'll focus on the X-component data, assuming the fiber is oriented along the X-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize DAS converter\n",
    "das_converter = DASConverter()\n",
    "\n",
    "# Convert X-component data to DAS strain rate\n",
    "das_data = das_converter.convert_numpy(\n",
    "    data_x,  # X-component velocity data\n",
    "    gauge_length=gauge_length,\n",
    "    channel_spacing=channel_spacing,\n",
    "    dt=times[1] - times[0]  # Time step\n",
    ")\n",
    "\n",
    "print(f\"Converted {das_data.shape[0]} channels of DAS data, each with {das_data.shape[1]} time steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize a single DAS channel\n",
    "channel_idx = 50  # Middle channel\n",
    "plot_seismic_trace(times, das_data[channel_idx], \n",
    "                  title=f\"DAS Strain Rate - Channel {channel_idx+1}\",\n",
    "                  xlabel=\"Time (s)\", ylabel=\"Strain Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot the DAS gather (all channels)\n",
    "plot_seismic_gather(das_data, title=\"DAS Strain Rate Gather\", \n",
    "                   xlabel=\"Time Sample\", ylabel=\"Channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Geophone and DAS Data\n",
    "\n",
    "Let's compare the geophone (particle velocity) data with the derived DAS (strain rate) data to understand the relationship between these two measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Normalize data for comparison\n",
    "def normalize(data):\n",
    "    \"\"\"Normalize data to [-1, 1] range.\"\"\"\n",
    "    for i in range(data.shape[0]):\n",
    "        max_val = np.max(np.abs(data[i, :]))\n",
    "        if max_val > 0:\n",
    "            data[i, :] = data[i, :] / max_val\n",
    "    return data\n",
    "\n",
    "# Normalize both datasets\n",
    "norm_geo_data = normalize(data_x.copy())\n",
    "norm_das_data = normalize(das_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare geophone and DAS data for a single channel\n",
    "channel_idx = 50  # Middle channel\n",
    "\n",
    "plot_multiple_traces(\n",
    "    times, \n",
    "    [norm_geo_data[channel_idx], norm_das_data[channel_idx]], \n",
    "    labels=[\"Geophone (Velocity)\", \"DAS (Strain Rate)\"],\n",
    "    title=f\"Comparison of Geophone and DAS Data - Channel {channel_idx+1}\",\n",
    "    xlabel=\"Time (s)\", \n",
    "    ylabel=\"Normalized Amplitude\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot side-by-side comparison of the gathers\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Plot geophone data\n",
    "im1 = ax1.imshow(norm_geo_data, aspect='auto', cmap='seismic')\n",
    "ax1.set_title(\"Geophone (Velocity)\")\n",
    "ax1.set_xlabel(\"Time Sample\")\n",
    "ax1.set_ylabel(\"Channel\")\n",
    "plt.colorbar(im1, ax=ax1)\n",
    "\n",
    "# Plot DAS data\n",
    "im2 = ax2.imshow(norm_das_data, aspect='auto', cmap='seismic')\n",
    "ax2.set_title(\"DAS (Strain Rate)\")\n",
    "ax2.set_xlabel(\"Time Sample\")\n",
    "plt.colorbar(im2, ax=ax2)\n",
    "\n",
    "plt.suptitle(\"Comparison of Geophone and DAS Data\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Differences\n",
    "\n",
    "Let's analyze the spectral differences between geophone and DAS data to better understand how they differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze frequency content\n",
    "from scipy import signal\n",
    "\n",
    "# Select a channel for analysis\n",
    "channel_idx = 50\n",
    "\n",
    "# Compute power spectral density for both geophone and DAS data\n",
    "fs = 1.0 / (times[1] - times[0])  # Sampling frequency\n",
    "f_geo, psd_geo = signal.welch(norm_geo_data[channel_idx], fs, nperseg=1024)\n",
    "f_das, psd_das = signal.welch(norm_das_data[channel_idx], fs, nperseg=1024)\n",
    "\n",
    "# Plot the spectra\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.semilogy(f_geo, psd_geo, label='Geophone')\n",
    "plt.semilogy(f_das, psd_das, label='DAS')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('PSD (power/Hz)')\n",
    "plt.title(f'Power Spectral Density - Channel {channel_idx+1}')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compute coherence between geophone and DAS data\n",
    "f, coh = signal.coherence(norm_geo_data[channel_idx], norm_das_data[channel_idx], fs, nperseg=1024)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(f, coh)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Coherence')\n",
    "plt.title(f'Coherence between Geophone and DAS - Channel {channel_idx+1}')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Gauge Length\n",
    "\n",
    "Let's explore how changing the gauge length affects the DAS response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Try different gauge lengths\n",
    "gauge_lengths = [5.0, 10.0, 20.0, 40.0]  # Gauge lengths in meters\n",
    "das_multi_gauge = []\n",
    "\n",
    "for gl in gauge_lengths:\n",
    "    das_data_gl = das_converter.convert_numpy(\n",
    "        data_x,\n",
    "        gauge_length=gl,\n",
    "        channel_spacing=channel_spacing,\n",
    "        dt=times[1] - times[0]\n",
    "    )\n",
    "    # Normalize and store for the selected channel\n",
    "    das_multi_gauge.append(normalize(das_data_gl.copy())[channel_idx])\n",
    "\n",
    "# Plot comparison of different gauge lengths for a single channel\n",
    "labels = [f\"Gauge Length = {gl} m\" for gl in gauge_lengths]\n",
    "plot_multiple_traces(\n",
    "    times, \n",
    "    das_multi_gauge, \n",
    "    labels=labels,\n",
    "    title=f\"DAS Response for Different Gauge Lengths - Channel {channel_idx+1}\",\n",
    "    xlabel=\"Time (s)\", \n",
    "    ylabel=\"Normalized Amplitude\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DAS Data for Interpolation Model\n",
    "\n",
    "Now that we have generated and analyzed the DAS data, let's save it for use in the interpolation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save DAS data\n",
    "np.save(Path(processed_das_dir) / \"das_data.npy\", das_data)\n",
    "\n",
    "# Save DAS metadata\n",
    "das_metadata = {\n",
    "    \"gauge_length\": gauge_length,\n",
    "    \"channel_spacing\": channel_spacing,\n",
    "    \"n_channels\": das_data.shape[0],\n",
    "    \"n_time_steps\": das_data.shape[1],\n",
    "    \"dt\": times[1] - times[0],\n",
    "    \"t_start\": times[0],\n",
    "    \"t_end\": times[-1]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "pd.DataFrame([das_metadata]).to_csv(Path(processed_das_dir) / \"das_metadata.csv\", index=False)\n",
    "\n",
    "print(f\"Saved DAS data to {processed_das_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Combined Dataset for Model Training\n",
    "\n",
    "Finally, let's create a combined dataset containing both geophone and DAS data, aligned in space and time, for use in the interpolation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a combined dataset\n",
    "combined_data = {\n",
    "    \"times\": times,\n",
    "    \"geophone_data\": data_x,  # X-component only\n",
    "    \"das_data\": das_data,\n",
    "    \"station_coordinates\": station_df[[\"lat\", \"lon\", \"elevation\"]].values,\n",
    "    \"metadata\": {\n",
    "        \"gauge_length\": gauge_length,\n",
    "        \"channel_spacing\": channel_spacing,\n",
    "        \"dt\": times[1] - times[0],\n",
    "        \"n_geophones\": data_x.shape[0],\n",
    "        \"n_das_channels\": das_data.shape[0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the combined dataset\n",
    "np.save(Path(processed_geo_dir) / \"combined_dataset.npy\", combined_data)\n",
    "print(f\"Saved combined dataset to {processed_geo_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Loaded synthetic geophone data generated by SPECFEM3D\n",
    "2. Converted particle velocity to DAS strain rate\n",
    "3. Visualized and compared geophone and DAS measurements\n",
    "4. Analyzed the spectral differences between the two data types\n",
    "5. Explored the impact of different gauge lengths on DAS response\n",
    "6. Saved the processed data for use in the interpolation model\n",
    "\n",
    "The generated DAS data, alongside the synthetic geophone data, will now be used to train the multimodal interpolation model to fill in missing geophone channels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}