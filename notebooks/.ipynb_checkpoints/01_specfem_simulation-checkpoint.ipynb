{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECFEM3D Simulation for Seismic Data Generation\n",
    "\n",
    "This notebook demonstrates how to set up and run SPECFEM3D simulations to generate synthetic seismic data for the interpolation project. We'll go through the following steps:\n",
    "\n",
    "1. Set up velocity models\n",
    "2. Configure SPECFEM3D input files (Par_file, source, stations)\n",
    "3. Run the simulation\n",
    "4. Process and visualize the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.simulation.specfem_runner import SpecfemSimulation\n",
    "from src.utils.logging_utils import setup_logging\n",
    "from src.utils.plot_utils import plot_seismic_trace, plot_seismic_gather\n",
    "\n",
    "# Set up logging\n",
    "logger = setup_logging(level='INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Define paths and parameters for the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECFEM3D directory: /home/masa/specfem3d\n",
      "Project root: /home/masa/ml_interpolation\n",
      "Output directory: /home/masa/ml_interpolation/data/synthetic/raw/simulation1\n",
      "Par_file template: /home/masa/ml_interpolation/specfem_simulations/Par_file_template\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "specfem_dir = os.path.expanduser(\"~/specfem3d\")  # Path to SPECFEM3D installation (converted to absolute path)\n",
    "\n",
    "# Get absolute paths\n",
    "notebook_dir = os.path.abspath(os.path.dirname('__file__'))\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "output_dir = os.path.join(project_root, \"data/synthetic/raw/simulation1\")  # Path to store outputs\n",
    "par_template = os.path.join(project_root, \"specfem_simulations/Par_file_template\")  # Template for Par_file\n",
    "\n",
    "print(f\"SPECFEM3D directory: {specfem_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Par_file template: {par_template}\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Also ensure specfem_simulations directory exists\n",
    "Path(os.path.join(project_root, \"specfem_simulations\")).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking SPECFEM3D executables:\n",
      "‚úì xmeshfem3D found at /home/masa/specfem3d/bin/xmeshfem3D\n",
      "‚úì xdecompose_mesh found at /home/masa/specfem3d/bin/xdecompose_mesh\n",
      "‚úì xspecfem3D found at /home/masa/specfem3d/bin/xspecfem3D\n",
      "Par_file_template found at ../specfem_simulations/Par_file_template\n"
     ]
    }
   ],
   "source": [
    "# Check if SPECFEM3D executables exist\n",
    "bindir = os.path.join(specfem_dir, \"bin\")\n",
    "executables = [\"xmeshfem3D\", \"xdecompose_mesh\", \"xspecfem3D\"]\n",
    "print(\"Checking SPECFEM3D executables:\")\n",
    "for exe in executables:\n",
    "    exe_path = os.path.join(bindir, exe)\n",
    "    if os.path.exists(exe_path):\n",
    "        print(f\"‚úì {exe} found at {exe_path}\")\n",
    "    else:\n",
    "        print(f\"‚úó {exe} NOT found at {exe_path}\")\n",
    "\n",
    "# Check if Par_file_template exists, if not copy it from SPECFEM3D installation\n",
    "par_template_path = Path(\"../specfem_simulations/Par_file_template\")\n",
    "if not par_template_path.exists():\n",
    "    print(f\"Par_file_template not found at {par_template_path}, copying from SPECFEM3D installation...\")\n",
    "    specfem_parfile = Path(specfem_dir) / \"DATA/Par_file\"\n",
    "    if specfem_parfile.exists():\n",
    "        import shutil\n",
    "        shutil.copy(specfem_parfile, par_template_path)\n",
    "        print(f\"Copied Par_file from {specfem_parfile} to {par_template_path}\")\n",
    "    else:\n",
    "        print(f\"ERROR: SPECFEM3D Par_file not found at {specfem_parfile}\")\n",
    "else:\n",
    "    print(f\"Par_file_template found at {par_template_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì MPI is installed: mpirun (Open MPI) 4.1.2\n"
     ]
    }
   ],
   "source": [
    "# Check for MPI support (required by SPECFEM3D)\n",
    "try:\n",
    "    # Try to execute mpirun to check if it's available\n",
    "    import subprocess\n",
    "    result = subprocess.run([\"mpirun\", \"--version\"], \n",
    "                          stdout=subprocess.PIPE, \n",
    "                          stderr=subprocess.PIPE,\n",
    "                          text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úì MPI is installed: {result.stdout.splitlines()[0]}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è MPI may not be installed or configured correctly\")\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not check MPI: {str(e)}\")\n",
    "    print(\"SPECFEM3D requires MPI for parallel execution. Make sure it's installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Velocity Model\n",
    "\n",
    "For this example, we'll use a simple layered model that SPECFEM3D can generate internally. In a real project, you might use a more complex model defined in your own files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores available: 32\n"
     ]
    }
   ],
   "source": [
    "# Define simulation parameters (these will be inserted into the Par_file)\n",
    "simulation_params = {\n",
    "    # General simulation parameters\n",
    "    \"NPROC\": 4,  # Number of MPI processes - set to 1 for troubleshooting\n",
    "    \"SIMULATION_TYPE\": 1,  # 1 = forward simulation\n",
    "    \"NSTEP\": 4000,  # Number of time steps\n",
    "    \"DT\": 0.001,  # Time step in seconds\n",
    "    \"MODEL\": \"default\",  # Model type\n",
    "    \"SAVE_FORWARD\": \".false.\",  # Don't save forward wavefield\n",
    "    \"USE_OLSEN_ATTENUATION\": \".false.\",  # No attenuation\n",
    "    \"NGNOD\": 8,  # Number of nodes per element\n",
    "    \"ABSORBING_CONDITIONS\": \".true.\",  # Absorbing boundary conditions\n",
    "    \"STACEY_ABSORBING_CONDITIONS\": \".true.\",  # Use Stacey absorbing boundary conditions\n",
    "    \"ATTENUATION\": \".false.\",  # No attenuation\n",
    "    \"USE_RICKER_TIME_FUNCTION\": \".true.\",  # Use Ricker wavelet\n",
    "    \n",
    "    # Output parameters\n",
    "    \"SAVE_SEISMOGRAMS_DISPLACEMENT\": \".true.\",  # Output displacement\n",
    "    \"NTSTEP_BETWEEN_OUTPUT_SEISMOS\": 10,  # Output seismograms every 10 steps\n",
    "    \"USE_BINARY_FOR_SEISMOGRAMS\": \".false.\",  # Save ASCII seismograms (*.semd files)\n",
    "    \"SAVE_BINARY_SEISMOGRAMS_SINGLE\": \".true.\",  # Save binary seismograms\n",
    "    \"SAVE_BINARY_SEISMOGRAMS_DOUBLE\": \".false.\",  # Don't save double precision binary\n",
    "    \"USE_EXISTING_STATIONS\": \".true.\",  # Use the STATIONS file we created\n",
    "    \n",
    "    # Multiple run parameters\n",
    "    \"NUMBER_OF_SIMULTANEOUS_RUNS\": 1,  # Single run mode\n",
    "    \"BROADCAST_SAME_MESH_AND_MODEL\": \".true.\",  # Required by newer SPECFEM3D versions\n",
    "    \n",
    "    # Cartesian mesh parameters (REQUIRED for xmeshfem3D)\n",
    "    \"LATITUDE_MIN\": 0.0,  # Min X coordinate of mesh\n",
    "    \"LATITUDE_MAX\": 2000.0,  # Max X coordinate of mesh\n",
    "    \"LONGITUDE_MIN\": 0.0,  # Min Y coordinate of mesh\n",
    "    \"LONGITUDE_MAX\": 2000.0,  # Max Y coordinate of mesh\n",
    "    \"DEPTH_MIN\": 0.0,  # Min Z coordinate of mesh (depth positive downward)\n",
    "    \"DEPTH_MAX\": 2000.0,  # Max Z coordinate of mesh\n",
    "    \"NEX_XI\": 40,  # Number of elements along X direction\n",
    "    \"NEX_ETA\": 40,  # Number of elements along Y direction\n",
    "    \"NEX_ZETA\": 40,  # Number of elements along Z direction\n",
    "}\n",
    "\n",
    "# Get number of CPU cores for potential NPROC adjustment\n",
    "try:\n",
    "    import multiprocessing\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    print(f\"Number of CPU cores available: {cpu_count}\")\n",
    "    if simulation_params[\"NPROC\"] > cpu_count:\n",
    "        print(f\"‚ö†Ô∏è Warning: NPROC ({simulation_params['NPROC']}) is greater than available CPU cores ({cpu_count})\")\n",
    "        print(\"   Consider reducing NPROC to avoid performance issues\")\n",
    "except:\n",
    "    print(\"Could not determine CPU count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECFEM3D will run with:\n",
      "- NPROC = 4\n",
      "- NSTEP = 4000\n",
      "- DT = 0.001\n",
      "- MODEL = default\n",
      "- Mesh size: 40 x 40 x 40 elements\n",
      "- Domain: X=[0.0,2000.0], Y=[0.0,2000.0], Z=[0.0,2000.0]\n",
      "‚úì ASCII seismograms will be saved\n",
      "\n",
      "Verify that these settings match your SPECFEM3D compilation configuration.\n",
      "If you encounter errors, you may need to adjust NPROC to match how SPECFEM3D was compiled.\n"
     ]
    }
   ],
   "source": [
    "# Show SPECFEM3D execution info\n",
    "print(\"SPECFEM3D will run with:\")\n",
    "print(f\"- NPROC = {simulation_params['NPROC']}\")\n",
    "print(f\"- NSTEP = {simulation_params['NSTEP']}\")\n",
    "print(f\"- DT = {simulation_params['DT']}\")\n",
    "print(f\"- MODEL = {simulation_params['MODEL']}\")\n",
    "print(f\"- Mesh size: {simulation_params['NEX_XI']} x {simulation_params['NEX_ETA']} x {simulation_params['NEX_ZETA']} elements\")\n",
    "print(f\"- Domain: X=[{simulation_params['LATITUDE_MIN']},{simulation_params['LATITUDE_MAX']}], \"\n",
    "      f\"Y=[{simulation_params['LONGITUDE_MIN']},{simulation_params['LONGITUDE_MAX']}], \"\n",
    "      f\"Z=[{simulation_params['DEPTH_MIN']},{simulation_params['DEPTH_MAX']}]\")\n",
    "\n",
    "# Check if required properties are enabled for output\n",
    "if 'USE_BINARY_FOR_SEISMOGRAMS' in simulation_params and simulation_params['USE_BINARY_FOR_SEISMOGRAMS'] == '.false.':\n",
    "    print(\"‚úì ASCII seismograms will be saved\")\n",
    "else:\n",
    "    print(\"‚úó ASCII seismograms will NOT be saved - this may affect output\")\n",
    "    \n",
    "print(\"\\nVerify that these settings match your SPECFEM3D compilation configuration.\")\n",
    "print(\"If you encounter errors, you may need to adjust NPROC to match how SPECFEM3D was compiled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Source Parameters\n",
    "\n",
    "Define the seismic source (location, type, etc.) for the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source parameters\n",
    "source_params = {\n",
    "    \"source_surf\": 0,  # Source is inside the medium\n",
    "    \"xs\": 1000.0,  # X position in meters\n",
    "    \"ys\": 1000.0,  # Y position in meters\n",
    "    \"zs\": 500.0,  # Z position in meters (depth positive downward)\n",
    "    \"source_type\": 1,  # 1 = force, 2 = moment tensor\n",
    "    \"time_function_type\": 2,  # Ricker wavelet\n",
    "    \"name_of_source_file\": \"\",  # Not used for simple source\n",
    "    \"burst_band_width\": 0.0,  # Not used for Ricker wavelet\n",
    "    \"f0\": 10.0,  # Central frequency in Hz\n",
    "    \"tshift\": 0.0,  # Time shift\n",
    "    \"anglesource\": 0.0,  # If source_type = 1, angle of force source\n",
    "    \"Mxx\": 1.0,  # If source_type = 2, moment tensor components\n",
    "    \"Mxy\": 0.0,\n",
    "    \"Mxz\": 0.0,\n",
    "    \"Myy\": 1.0,\n",
    "    \"Myz\": 0.0,\n",
    "    \"Mzz\": 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Station Locations\n",
    "\n",
    "Define the locations of the receivers (geophones). We'll create a linear array to simulate a geophone line and a DAS fiber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>network</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elevation</th>\n",
       "      <th>burial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST001</td>\n",
       "      <td>GE</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ST002</td>\n",
       "      <td>GE</td>\n",
       "      <td>510.10101</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST003</td>\n",
       "      <td>GE</td>\n",
       "      <td>520.20202</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST004</td>\n",
       "      <td>GE</td>\n",
       "      <td>530.30303</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST005</td>\n",
       "      <td>GE</td>\n",
       "      <td>540.40404</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name network        lat     lon  elevation  burial\n",
       "0  ST001      GE  500.00000  1000.0        0.0     0.0\n",
       "1  ST002      GE  510.10101  1000.0        0.0     0.0\n",
       "2  ST003      GE  520.20202  1000.0        0.0     0.0\n",
       "3  ST004      GE  530.30303  1000.0        0.0     0.0\n",
       "4  ST005      GE  540.40404  1000.0        0.0     0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define station locations for a linear array\n",
    "n_stations = 100  # Number of stations\n",
    "start_x = 500.0  # Start X position in meters\n",
    "end_x = 1500.0  # End X position in meters\n",
    "y_position = 1000.0  # Y position in meters\n",
    "depth = 0.0  # Depth in meters (surface)\n",
    "\n",
    "# Generate evenly spaced station locations\n",
    "x_positions = np.linspace(start_x, end_x, n_stations)\n",
    "\n",
    "# Create station list\n",
    "stations_list = []\n",
    "for i, x in enumerate(x_positions):\n",
    "    stations_list.append({\n",
    "        \"name\": f\"ST{i+1:03d}\",  # Station name\n",
    "        \"network\": \"GE\",  # Network name\n",
    "        \"lat\": x,  # Using X as a proxy for latitude\n",
    "        \"lon\": y_position,  # Using Y as a proxy for longitude\n",
    "        \"elevation\": 0.0,  # Elevation\n",
    "        \"burial\": depth  # Burial depth\n",
    "    })\n",
    "\n",
    "# Show first few stations\n",
    "pd.DataFrame(stations_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing deep clean of SPECFEM3D in /home/masa/specfem3d...\n",
      "Removing and recreating /home/masa/specfem3d/OUTPUT_FILES...\n",
      "Cleaning /home/masa/specfem3d/DATA...\n",
      "  Removed file: Mesh_Par_file\n",
      "  Removed file: SOURCE\n",
      "  Removed file: Par_file\n",
      "  Restored file: CMTSOLUTION\n",
      "  Restored file: STATIONS\n",
      "Deep clean completed.\n"
     ]
    }
   ],
   "source": [
    "# First run a deep clean of SPECFEM files to ensure a clean state\n",
    "def deep_clean_specfem():\n",
    "    \"\"\"Perform a deep clean of SPECFEM3D output files and databases.\"\"\"\n",
    "    import subprocess\n",
    "    import shutil\n",
    "    import os\n",
    "    \n",
    "    print(f\"Performing deep clean of SPECFEM3D in {specfem_dir}...\")\n",
    "    \n",
    "    # Full path to OUTPUT_FILES\n",
    "    output_dir = os.path.join(specfem_dir, \"OUTPUT_FILES\")\n",
    "    \n",
    "    # 1. Clean the entire OUTPUT_FILES directory\n",
    "    if os.path.exists(output_dir):\n",
    "        print(f\"Removing and recreating {output_dir}...\")\n",
    "        shutil.rmtree(output_dir)\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # 2. Recreate DATABASES_MPI directory\n",
    "    db_dir = os.path.join(output_dir, \"DATABASES_MPI\")\n",
    "    os.makedirs(db_dir, exist_ok=True)\n",
    "    \n",
    "    # 3. Remove all DATA files except the ones we need to preserve\n",
    "    data_dir = os.path.join(specfem_dir, \"DATA\")\n",
    "    print(f\"Cleaning {data_dir}...\")\n",
    "    \n",
    "    # Make backup copies of important files\n",
    "    backup_files = {}\n",
    "    for file in [\"CMTSOLUTION\", \"STATIONS\", \"STATIONS_ADJOINT\", \"STATIONS_FILTERED\"]:\n",
    "        filepath = os.path.join(data_dir, file)\n",
    "        if os.path.exists(filepath) and os.path.isfile(filepath):\n",
    "            with open(filepath, 'r') as f:\n",
    "                backup_files[file] = f.read()\n",
    "    \n",
    "    # Reset the DATA directory to a clean state\n",
    "    for item in os.listdir(data_dir):\n",
    "        if item not in [\"CMTSOLUTION\", \"STATIONS\", \"STATIONS_ADJOINT\", \"STATIONS_FILTERED\"]:\n",
    "            itempath = os.path.join(data_dir, item)\n",
    "            if os.path.isfile(itempath):\n",
    "                try:\n",
    "                    os.remove(itempath)\n",
    "                    print(f\"  Removed file: {item}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Warning: Could not remove {item}: {e}\")\n",
    "    \n",
    "    # Restore backup files\n",
    "    for file, content in backup_files.items():\n",
    "        filepath = os.path.join(data_dir, file)\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write(content)\n",
    "            print(f\"  Restored file: {file}\")\n",
    "    \n",
    "    print(\"Deep clean completed.\")\n",
    "\n",
    "# Run the deep clean\n",
    "deep_clean_specfem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set NPROC to 4\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - WARNING - Parameter 'SAVE_BINARY_SEISMOGRAMS_SINGLE' not found in Par_file template. Skipping.\n",
      "Warning: Parameter 'SAVE_BINARY_SEISMOGRAMS_SINGLE' not found in Par_file template. Skipping.\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - WARNING - Parameter 'SAVE_BINARY_SEISMOGRAMS_DOUBLE' not found in Par_file template. Skipping.\n",
      "Warning: Parameter 'SAVE_BINARY_SEISMOGRAMS_DOUBLE' not found in Par_file template. Skipping.\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - WARNING - Parameter 'USE_EXISTING_STATIONS' not found in Par_file template. Skipping.\n",
      "Warning: Parameter 'USE_EXISTING_STATIONS' not found in Par_file template. Skipping.\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - WARNING - Par_file is missing required parameters: NPROC, MODEL, NGNOD, LATITUDE_MIN, LATITUDE_MAX, LONGITUDE_MIN, LONGITUDE_MAX, DEPTH_MIN, DEPTH_MAX, NEX_XI, NEX_ETA, NPROC_XI, NPROC_ETA\n",
      "Warning: Par_file is missing required parameters: NPROC, MODEL, NGNOD, LATITUDE_MIN, LATITUDE_MAX, LONGITUDE_MIN, LONGITUDE_MAX, DEPTH_MIN, DEPTH_MAX, NEX_XI, NEX_ETA, NPROC_XI, NPROC_ETA\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - INFO - Prepared Par_file at /home/masa/ml_interpolation/data/synthetic/raw/simulation1/Par_file\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - INFO - Prepared SOURCE file at /home/masa/ml_interpolation/data/synthetic/raw/simulation1/SOURCE\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - INFO - Prepared STATIONS file with 100 stations\n",
      "Prepared Par_file: /home/masa/ml_interpolation/data/synthetic/raw/simulation1/Par_file\n",
      "Prepared SOURCE file: /home/masa/ml_interpolation/data/synthetic/raw/simulation1/SOURCE\n",
      "Prepared STATIONS file: /home/masa/ml_interpolation/data/synthetic/raw/simulation1/STATIONS\n",
      "\n",
      "Verifying Par_file content:\n",
      "‚úì BROADCAST_SAME_MESH_AND_MODEL found in Par_file\n",
      "  Value: .true.\n"
     ]
    }
   ],
   "source": [
    "# Initialize SPECFEM simulation\n",
    "sim = SpecfemSimulation(specfem_dir, output_dir)\n",
    "\n",
    "# Prepare input files\n",
    "par_file = sim.prepare_parfile(par_template, simulation_params)\n",
    "source_file = sim.prepare_source(source_params)\n",
    "stations_file = sim.prepare_stations(stations_list)\n",
    "\n",
    "print(f\"Prepared Par_file: {par_file}\")\n",
    "print(f\"Prepared SOURCE file: {source_file}\")\n",
    "print(f\"Prepared STATIONS file: {stations_file}\")\n",
    "\n",
    "# Verify PAR_FILE content for debugging\n",
    "print(\"\\nVerifying Par_file content:\")\n",
    "with open(par_file, 'r') as f:\n",
    "    content = f.read()\n",
    "    # Check for BROADCAST_SAME_MESH_AND_MODEL in the file\n",
    "    if \"BROADCAST_SAME_MESH_AND_MODEL\" in content:\n",
    "        print(\"‚úì BROADCAST_SAME_MESH_AND_MODEL found in Par_file\")\n",
    "        # Extract the value\n",
    "        import re\n",
    "        match = re.search(r'BROADCAST_SAME_MESH_AND_MODEL\\s*=\\s*(\\.true\\.|\\.false\\.)', content)\n",
    "        if match:\n",
    "            print(f\"  Value: {match.group(1)}\")\n",
    "    else:\n",
    "        print(\"‚úó BROADCAST_SAME_MESH_AND_MODEL NOT found in Par_file - adding it\")\n",
    "        # Add the parameter to the file if it's missing\n",
    "        with open(par_file, 'a') as f_append:\n",
    "            f_append.write(\"\\n# Added by debugging script\\nBROADCAST_SAME_MESH_AND_MODEL   = .true.\\n\")\n",
    "        print(\"  Parameter added to Par_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running full SPECFEM3D simulation...\n",
      "Cleaning previous simulation outputs...\n",
      "Cleaned DATABASES_MPI directory\n",
      "Cleaned OUTPUT_FILES directory\n",
      "Set NPROC to 4\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - WARNING - Parameter 'SAVE_BINARY_SEISMOGRAMS_SINGLE' not found in Par_file template. Skipping.\n",
      "Warning: Parameter 'SAVE_BINARY_SEISMOGRAMS_SINGLE' not found in Par_file template. Skipping.\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - WARNING - Parameter 'SAVE_BINARY_SEISMOGRAMS_DOUBLE' not found in Par_file template. Skipping.\n",
      "Warning: Parameter 'SAVE_BINARY_SEISMOGRAMS_DOUBLE' not found in Par_file template. Skipping.\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - WARNING - Parameter 'USE_EXISTING_STATIONS' not found in Par_file template. Skipping.\n",
      "Warning: Parameter 'USE_EXISTING_STATIONS' not found in Par_file template. Skipping.\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - WARNING - Par_file is missing required parameters: NPROC, MODEL, NGNOD, LATITUDE_MIN, LATITUDE_MAX, LONGITUDE_MIN, LONGITUDE_MAX, DEPTH_MIN, DEPTH_MAX, NEX_XI, NEX_ETA, NPROC_XI, NPROC_ETA\n",
      "Warning: Par_file is missing required parameters: NPROC, MODEL, NGNOD, LATITUDE_MIN, LATITUDE_MAX, LONGITUDE_MIN, LONGITUDE_MAX, DEPTH_MIN, DEPTH_MAX, NEX_XI, NEX_ETA, NPROC_XI, NPROC_ETA\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - INFO - Prepared Par_file at /home/masa/ml_interpolation/data/synthetic/raw/simulation1/Par_file\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - INFO - Prepared SOURCE file at /home/masa/ml_interpolation/data/synthetic/raw/simulation1/SOURCE\n",
      "2025-03-21 21:56:24 - src.simulation.specfem_runner - INFO - Prepared STATIONS file with 100 stations\n",
      "Created dedicated Mesh_Par_file at /home/masa/specfem3d/DATA/Mesh_Par_file\n",
      "Copied Mesh_Par_file to /home/masa/specfem3d/DATA/meshfem3D_files/Mesh_Par_file\n",
      "Created interfaces.dat at /home/masa/specfem3d/DATA/meshfem3D_files/interfaces.dat\n",
      "Created no_cavity.dat at /home/masa/specfem3d/DATA/meshfem3D_files/no_cavity.dat\n",
      "Verifying file existence before running mesher:\n",
      "  Par_file exists: True\n",
      "  Mesh_Par_file exists: True\n",
      "Running xmeshfem3D...\n",
      "Executing: mpirun -np 4 ./bin/xmeshfem3D\n",
      "2025-03-21 21:56:26 - src.simulation.specfem_runner - ERROR - Meshing failed: STOP Error: some parameters are missing in your Par_file, it is incomplete or in an older format, see at the end of the standard output file of the run for detailed and easy instructions about how to fix that\n",
      "--------------------------------------------------------------------------\n",
      "mpirun has exited due to process rank 0 with PID 0 on\n",
      "node masa-ubuntu22 exiting improperly. There are three reasons this could occur:\n",
      "\n",
      "1. this process did not call \"init\" before exiting, but others in\n",
      "the job did. This can cause a job to hang indefinitely while it waits\n",
      "for all processes to call \"init\". By rule, if one process calls \"init\",\n",
      "then ALL processes must call \"init\" prior to termination.\n",
      "\n",
      "2. this process called \"init\", but exited without calling \"finalize\".\n",
      "By rule, all processes that call \"init\" MUST call \"finalize\" prior to\n",
      "exiting or it will be considered an \"abnormal termination\"\n",
      "\n",
      "3. this process called \"MPI_Abort\" or \"orte_abort\" and the mca parameter\n",
      "orte_create_session_dirs is set to false. In this case, the run-time cannot\n",
      "detect that the abort call was an abnormal termination. Hence, the only\n",
      "error message you will receive is this one.\n",
      "\n",
      "This may have caused other processes in the application to be\n",
      "terminated by signals sent by mpirun (as reported here).\n",
      "\n",
      "You can avoid this message by specifying -quiet on the mpirun command line.\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Meshing failed: STOP Error: some parameters are missing in your Par_file, it is incomplete or in an older format, see at the end of the standard output file of the run for detailed and easy instructions about how to fix that\n",
      "--------------------------------------------------------------------------\n",
      "mpirun has exited due to process rank 0 with PID 0 on\n",
      "node masa-ubuntu22 exiting improperly. There are three reasons this could occur:\n",
      "\n",
      "1. this process did not call \"init\" before exiting, but others in\n",
      "the job did. This can cause a job to hang indefinitely while it waits\n",
      "for all processes to call \"init\". By rule, if one process calls \"init\",\n",
      "then ALL processes must call \"init\" prior to termination.\n",
      "\n",
      "2. this process called \"init\", but exited without calling \"finalize\".\n",
      "By rule, all processes that call \"init\" MUST call \"finalize\" prior to\n",
      "exiting or it will be considered an \"abnormal termination\"\n",
      "\n",
      "3. this process called \"MPI_Abort\" or \"orte_abort\" and the mca parameter\n",
      "orte_create_session_dirs is set to false. In this case, the run-time cannot\n",
      "detect that the abort call was an abnormal termination. Hence, the only\n",
      "error message you will receive is this one.\n",
      "\n",
      "This may have caused other processes in the application to be\n",
      "terminated by signals sent by mpirun (as reported here).\n",
      "\n",
      "You can avoid this message by specifying -quiet on the mpirun command line.\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "‚ùå Simulation failed. Check logs for details.\n"
     ]
    }
   ],
   "source": [
    "# Run the full simulation (mesher, partitioner, solver) in one step\n",
    "print(\"Running full SPECFEM3D simulation...\")\n",
    "\n",
    "# Make sure BROADCAST_SAME_MESH_AND_MODEL is set by directly writing to the Par_file \n",
    "# before running the simulation\n",
    "par_file_path = os.path.join(output_dir, \"Par_file\")\n",
    "with open(par_file_path, 'r') as f:\n",
    "    par_content = f.read()\n",
    "\n",
    "# Ensure BROADCAST_SAME_MESH_AND_MODEL is present and set correctly\n",
    "if \"BROADCAST_SAME_MESH_AND_MODEL\" not in par_content:\n",
    "    with open(par_file_path, 'a') as f:\n",
    "        f.write(\"\\n# Added for compatibility\\nBROADCAST_SAME_MESH_AND_MODEL   = .true.\\n\")\n",
    "    print(\"Added BROADCAST_SAME_MESH_AND_MODEL to Par_file\")\n",
    "\n",
    "# Add other required parameters if missing\n",
    "required_params = {\n",
    "    \"NPROC_XI\": \"2\",  # Must match total NPROC when multiplied by NPROC_ETA\n",
    "    \"NPROC_ETA\": \"2\", \n",
    "    \"SUPPRESS_UTM_PROJECTION\": \".true.\"\n",
    "}\n",
    "\n",
    "for param, value in required_params.items():\n",
    "    if param not in par_content:\n",
    "        with open(par_file_path, 'a') as f:\n",
    "            f.write(f\"\\n# Added for compatibility\\n{param}   = {value}\\n\")\n",
    "        print(f\"Added {param} = {value} to Par_file\")\n",
    "\n",
    "# Now run the full simulation\n",
    "success = sim.run_full_simulation(par_template, simulation_params, source_params, stations_list)\n",
    "\n",
    "if success:\n",
    "    print(\"‚úÖ Full simulation completed successfully!\")\n",
    "    print(f\"Output files copied to {output_dir}\")\n",
    "else:\n",
    "    print(\"‚ùå Simulation failed. Check logs for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par_file exists: True\n",
      "Mesh_Par_file exists: True\n",
      "‚úì LONGITUDE_MIN found in Par_file\n",
      "‚úì LONGITUDE_MAX found in Par_file\n",
      "‚úì LATITUDE_MIN found in Par_file\n",
      "‚úì LATITUDE_MAX found in Par_file\n",
      "‚úì DEPTH_MIN found in Par_file\n",
      "‚úì DEPTH_MAX found in Par_file\n",
      "‚úì NEX_XI found in Par_file\n",
      "‚úì NEX_ETA found in Par_file\n",
      "‚úì NEX_ZETA found in Par_file\n"
     ]
    }
   ],
   "source": [
    "# Helper function to check SPECFEM3D error logs\n",
    "def check_specfem_error_logs():\n",
    "    \"\"\"Check SPECFEM3D error logs for common issues.\"\"\"\n",
    "    error_file = os.path.join(specfem_dir, \"OUTPUT_FILES/error_message000000.txt\")\n",
    "    output_solver = os.path.join(specfem_dir, \"OUTPUT_FILES/output_solver.txt\")\n",
    "    mesh_parfile = os.path.join(specfem_dir, \"DATA/Mesh_Par_file\")\n",
    "    parfile = os.path.join(specfem_dir, \"DATA/Par_file\")\n",
    "    \n",
    "    # Check mesh and Par files first\n",
    "    print(f\"Par_file exists: {os.path.exists(parfile)}\")\n",
    "    print(f\"Mesh_Par_file exists: {os.path.exists(mesh_parfile)}\")\n",
    "    \n",
    "    if os.path.exists(parfile):\n",
    "        # Check for essential Cartesian parameters\n",
    "        with open(parfile, 'r') as f:\n",
    "            content = f.read()\n",
    "            for param in [\"LONGITUDE_MIN\", \"LONGITUDE_MAX\", \"LATITUDE_MIN\", \"LATITUDE_MAX\", \n",
    "                          \"DEPTH_MIN\", \"DEPTH_MAX\", \"NEX_XI\", \"NEX_ETA\", \"NEX_ZETA\"]:\n",
    "                if param in content:\n",
    "                    print(f\"‚úì {param} found in Par_file\")\n",
    "                else:\n",
    "                    print(f\"‚úó {param} NOT found in Par_file - this will cause mesher errors!\")\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    # Check error message file\n",
    "    if os.path.exists(error_file):\n",
    "        with open(error_file, 'r') as f:\n",
    "            error_content = f.read()\n",
    "            print(f\"Error message content: {error_content}\")\n",
    "            errors.append(error_content)\n",
    "    \n",
    "    # Check solver output\n",
    "    if os.path.exists(output_solver):\n",
    "        with open(output_solver, 'r') as f:\n",
    "            solver_output = f.read()\n",
    "            print(f\"Solver output: {solver_output}\")\n",
    "    \n",
    "    # Check for specific error patterns\n",
    "    if errors:\n",
    "        if any(\"wrong number of MPI processes\" in e for e in errors):\n",
    "            print(\"\\nüîç DIAGNOSIS: MPI process count mismatch detected\")\n",
    "            print(\"   Possible causes:\")\n",
    "            print(\"   1. NPROC in Par_file doesn't match MPI processes used for execution\")\n",
    "            print(\"   2. Previous simulation files with different NPROC still exist\")\n",
    "            print(\"   3. Need to explicitly use 'mpirun -np 1' for all SPECFEM3D executables\")\n",
    "            print(\"\\n   Suggested fixes:\")\n",
    "            print(\"   - Ensure consistent NPROC across all stages\")\n",
    "            print(\"   - Clear previous simulation outputs completely\")\n",
    "            print(\"   - Use 'mpirun -np 1' for all executables (mesher, partitioner, solver)\")\n",
    "        elif any(\"Error opening Mesh_Par_file\" in e for e in errors):\n",
    "            print(\"\\nüîç DIAGNOSIS: Mesh_Par_file not found\")\n",
    "            print(\"   Possible causes:\")\n",
    "            print(\"   1. The Mesh_Par_file wasn't copied to the right location\")\n",
    "            print(\"   2. The DATA directory structure is incorrect\")\n",
    "            print(\"\\n   Suggested fixes:\")\n",
    "            print(\"   - Ensure Par_file is copied to DATA/Mesh_Par_file\")\n",
    "            print(\"   - Check DATA directory permissions\")\n",
    "        elif any(\"Error reading Mesh parameter\" in e for e in errors):\n",
    "            print(\"\\nüîç DIAGNOSIS: Missing mesh parameters in Par_file\")\n",
    "            print(\"   The mesher is looking for specific parameters in Mesh_Par_file:\")\n",
    "            print(\"   - Make sure LONGITUDE_MIN, LONGITUDE_MAX, LATITUDE_MIN, LATITUDE_MAX, etc. are defined\")\n",
    "            print(\"   - These parameters are required for Cartesian meshes\")\n",
    "\n",
    "# Check error logs\n",
    "check_specfem_error_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mesher...\n",
      "Created complete Par_file at /home/masa/specfem3d/DATA/Par_file\n",
      "Created custom Mesh_Par_file at /home/masa/specfem3d/DATA/Mesh_Par_file\n",
      "Copied SOURCE and STATIONS files to SPECFEM3D DATA directory\n",
      "Created interfaces.dat and no_cavity.dat files\n",
      "Created DATABASES_MPI directory\n",
      "Running xmeshfem3D directly...\n",
      "TOMOGRAPHY_PATH                 = ./DATA/tomo_files/\n",
      "\n",
      "SEP_MODEL_DIRECTORY             = ./DATA/my_SEP_model/\n",
      "\n",
      "ATTENUATION_f0_REFERENCE        = 0.33333d0\n",
      "\n",
      "MIN_ATTENUATION_PERIOD          = 999999998.d0\n",
      "\n",
      "MAX_ATTENUATION_PERIOD          = 999999999.d0\n",
      "\n",
      "COMPUTE_FREQ_BAND_AUTOMATIC     = .true.\n",
      "\n",
      "USE_OLSEN_ATTENUATION           = .false.\n",
      "\n",
      "OLSEN_ATTENUATION_RATIO         = 0.05\n",
      "\n",
      "PML_CONDITIONS                  = .false.\n",
      "\n",
      "PML_INSTEAD_OF_FREE_SURFACE     = .false.\n",
      "\n",
      "f0_FOR_PML                      = 0.05555\n",
      "\n",
      "BOTTOM_FREE_SURFACE             = .false.\n",
      "\n",
      "UNDO_ATTENUATION_AND_OR_PML     = .false.\n",
      "\n",
      "NT_DUMP_ATTENUATION             = 500\n",
      "\n",
      "CREATE_SHAKEMAP                 = .false.\n",
      "\n",
      "MOVIE_SURFACE                   = .false.\n",
      "\n",
      "MOVIE_TYPE                      = 1\n",
      "\n",
      "MOVIE_VOLUME                    = .false.\n",
      "\n",
      "SAVE_DISPLACEMENT               = .false.\n",
      "\n",
      "USE_HIGHRES_FOR_MOVIES          = .false.\n",
      "\n",
      "NTSTEP_BETWEEN_FRAMES           = 200\n",
      "\n",
      "HDUR_MOVIE                      = 0.0\n",
      "\n",
      "SAVE_MESH_FILES                 = .false.\n",
      "\n",
      "LOCAL_PATH                      = OUTPUT_FILES/DATABASES_MPI\n",
      "\n",
      "NTSTEP_BETWEEN_OUTPUT_INFO      = 500\n",
      "\n",
      "USE_SOURCES_RECEIVERS_Z         = .false.\n",
      "\n",
      "USE_EXTERNAL_SOURCE_FILE        = .false.\n",
      "\n",
      "SAVE_SEISMOGRAMS_STRAIN         = .false.\n",
      "\n",
      "SAVE_SEISMOGRAMS_IN_ADJOINT_RUN = .false.\n",
      "\n",
      "USE_TRICK_FOR_BETTER_PRESSURE   = .false.\n",
      "\n",
      "USE_SOURCE_ENCODING             = .false.\n",
      "\n",
      "OUTPUT_ENERGY                   = .false.\n",
      "\n",
      "NTSTEP_BETWEEN_OUTPUT_ENERGY    = 10\n",
      "\n",
      "NTSTEP_BETWEEN_READ_ADJSRC      = 0\n",
      "\n",
      "READ_ADJSRC_ASDF               = .false.\n",
      "\n",
      "ANISOTROPIC_KL                  = .false.\n",
      "\n",
      "SAVE_TRANSVERSE_KL              = .false.\n",
      "\n",
      "ANISOTROPIC_VELOCITY_KL         = .false.\n",
      "\n",
      "APPROXIMATE_HESS_KL             = .false.\n",
      "\n",
      "SAVE_MOHO_MESH                  = .false.\n",
      "\n",
      "COUPLE_WITH_INJECTION_TECHNIQUE = .false.\n",
      "\n",
      "INJECTION_TECHNIQUE_TYPE        = 3\n",
      "\n",
      "MESH_A_CHUNK_OF_THE_EARTH       = .false.\n",
      "\n",
      "TRACTION_PATH                   = ./DATA/AxiSEM_tractions/3/\n",
      "\n",
      "FKMODEL_FILE                    = FKmodel\n",
      "\n",
      "RECIPROCITY_AND_KH_INTEGRAL     = .false.\n",
      "\n",
      "ADIOS_ENABLED                   = .false.\n",
      "\n",
      "ADIOS_FOR_DATABASES             = .false.\n",
      "\n",
      "ADIOS_FOR_MESH                  = .false.\n",
      "\n",
      "ADIOS_FOR_FORWARD_ARRAYS        = .false.\n",
      "\n",
      "ADIOS_FOR_KERNELS               = .false.\n",
      "\n",
      "ADIOS_FOR_UNDO_ATTENUATION      = .false.\n",
      "\n",
      "\n",
      " All the above parameters are missing from your Par_file.\n",
      " Please cut and paste them somewhere in your Par_file (any place is fine), change their values if needed\n",
      " (the above values are just default values), and restart your run.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STOP Error: some parameters are missing in your Par_file, it is incomplete or in an older format, see at the end of the standard output file of the run for detailed and easy instructions about how to fix that\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meshing failed - no mesh files found.\n",
      "Skipping partitioner and solver since meshing failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "mpirun has exited due to process rank 0 with PID 0 on\n",
      "node masa-ubuntu22 exiting improperly. There are three reasons this could occur:\n",
      "\n",
      "1. this process did not call \"init\" before exiting, but others in\n",
      "the job did. This can cause a job to hang indefinitely while it waits\n",
      "for all processes to call \"init\". By rule, if one process calls \"init\",\n",
      "then ALL processes must call \"init\" prior to termination.\n",
      "\n",
      "2. this process called \"init\", but exited without calling \"finalize\".\n",
      "By rule, all processes that call \"init\" MUST call \"finalize\" prior to\n",
      "exiting or it will be considered an \"abnormal termination\"\n",
      "\n",
      "3. this process called \"MPI_Abort\" or \"orte_abort\" and the mca parameter\n",
      "orte_create_session_dirs is set to false. In this case, the run-time cannot\n",
      "detect that the abort call was an abnormal termination. Hence, the only\n",
      "error message you will receive is this one.\n",
      "\n",
      "This may have caused other processes in the application to be\n",
      "terminated by signals sent by mpirun (as reported here).\n",
      "\n",
      "You can avoid this message by specifying -quiet on the mpirun command line.\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the mesher\n",
    "print(\"Running mesher...\")\n",
    "\n",
    "# Import shutil for file copying\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Create a complete Par_file with all required parameters\n",
    "complete_par_file = os.path.join(specfem_dir, \"DATA/Par_file\")\n",
    "with open(complete_par_file, 'w') as f:\n",
    "    f.write(\"\"\"#-----------------------------------------------------------\n",
    "#\n",
    "# Simulation input parameters\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# forward or adjoint simulation\n",
    "# 1 = forward, 2 = adjoint, 3 = both simultaneously\n",
    "SIMULATION_TYPE                 = 1\n",
    "# 0 = earthquake simulation,  1/2/3 = three steps in noise simulation\n",
    "NOISE_TOMOGRAPHY                = 0\n",
    "SAVE_FORWARD                    = .false.\n",
    "\n",
    "# solve a full FWI inverse problem from a single calling program with no I/Os, storing everything in memory,\n",
    "# or run a classical forward or adjoint problem only and save the seismograms and/or sensitivity kernels to disk (with costlier I/Os)\n",
    "INVERSE_FWI_FULL_PROBLEM        = .false.\n",
    "\n",
    "# UTM projection parameters\n",
    "# Use a negative zone number for the Southern hemisphere:\n",
    "# The Northern hemisphere corresponds to zones +1 to +60,\n",
    "# The Southern hemisphere corresponds to zones -1 to -60.\n",
    "UTM_PROJECTION_ZONE             = 11\n",
    "SUPPRESS_UTM_PROJECTION         = .true.\n",
    "\n",
    "# number of MPI processors\n",
    "NPROC                           = 4\n",
    "\n",
    "# time step parameters\n",
    "NSTEP                           = 4000\n",
    "DT                              = 0.001\n",
    "\n",
    "# set to true to use local-time stepping (LTS)\n",
    "LTS_MODE                        = .false.\n",
    "\n",
    "# Partitioning algorithm for decompose_mesh\n",
    "# choose partitioner: 1==SCOTCH (default), 2==METIS, 3==PATOH, 4==ROWS_PART\n",
    "PARTITIONING_TYPE               = 1\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "# LDDRK time scheme\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "USE_LDDRK                       = .false.\n",
    "INCREASE_CFL_FOR_LDDRK          = .false.\n",
    "RATIO_BY_WHICH_TO_INCREASE_IT   = 1.4\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "# Mesh\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# Number of nodes for 2D and 3D shape functions for hexahedra.\n",
    "# We use either 8-node mesh elements (bricks) or 27-node elements.\n",
    "# If you use our internal mesher, the only option is 8-node bricks (27-node elements are not supported).\n",
    "NGNOD                           = 8\n",
    "\n",
    "# models:\n",
    "# available options are:\n",
    "#   default (model parameters described by mesh properties)\n",
    "# 1D models available are:\n",
    "#   1d_prem,1d_socal,1d_cascadia\n",
    "# 3D models available are:\n",
    "#   aniso,external,gll,salton_trough,tomo,SEP,coupled,...\n",
    "MODEL                           = default\n",
    "\n",
    "# parameters describing the model\n",
    "APPROXIMATE_OCEAN_LOAD          = .false.\n",
    "TOPOGRAPHY                      = .false.\n",
    "ATTENUATION                     = .false.\n",
    "ANISOTROPY                      = .false.\n",
    "GRAVITY                         = .false.\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "# Parameters for the Cartesian mesh creation\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# Mesh dimensions for Cartesian grid (triplanar option)\n",
    "LATITUDE_MIN                    = 0.0\n",
    "LATITUDE_MAX                    = 2000.0\n",
    "LONGITUDE_MIN                   = 0.0\n",
    "LONGITUDE_MAX                   = 2000.0\n",
    "DEPTH_MIN                       = 0.0\n",
    "DEPTH_MAX                       = 2000.0\n",
    "\n",
    "# Number of elements along each edge\n",
    "NEX_XI                          = 40\n",
    "NEX_ETA                         = 40\n",
    "NEX_ZETA                        = 40\n",
    "\n",
    "# This affects the mesher but is not in Mesh_Par_file\n",
    "NPROC_XI                        = 2\n",
    "NPROC_ETA                       = 2\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "# Absorbing boundary conditions\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# Stacey absorbing boundary conditions for a regional simulation\n",
    "STACEY_ABSORBING_CONDITIONS     = .true.\n",
    "\n",
    "# absorbing top surface (defined in mesh as 'free_surface_file')\n",
    "STACEY_INSTEAD_OF_FREE_SURFACE  = .false.\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "# Sources\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# use a (tilted) FORCESOLUTION force point source (or several) instead of a CMTSOLUTION moment-tensor source.\n",
    "USE_FORCE_POINT_SOURCE          = .false.\n",
    "\n",
    "# set to true to use a Ricker source time function instead of the source time functions set by default\n",
    "# to represent a (tilted) FORCESOLUTION force point source or a CMTSOLUTION moment-tensor source.\n",
    "USE_RICKER_TIME_FUNCTION        = .true.\n",
    "\n",
    "# print source time function\n",
    "PRINT_SOURCE_TIME_FUNCTION      = .false.\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "# Seismograms\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# interval in time steps for writing of seismograms\n",
    "NTSTEP_BETWEEN_OUTPUT_SEISMOS   = 10\n",
    "\n",
    "# set to n to reduce the sampling rate of output seismograms by a factor of n\n",
    "# defaults to 1, which means no down-sampling\n",
    "NTSTEP_BETWEEN_OUTPUT_SAMPLE    = 1\n",
    "\n",
    "# decide if we save displacement, velocity, acceleration and/or pressure in forward runs (they can be set to true simultaneously)\n",
    "# currently pressure seismograms are implemented in acoustic (i.e. fluid) elements only\n",
    "SAVE_SEISMOGRAMS_DISPLACEMENT   = .true.\n",
    "SAVE_SEISMOGRAMS_VELOCITY       = .false.\n",
    "SAVE_SEISMOGRAMS_ACCELERATION   = .false.\n",
    "SAVE_SEISMOGRAMS_PRESSURE       = .false.   # currently implemented in acoustic (i.e. fluid) elements only\n",
    "\n",
    "# save seismograms in binary or ASCII format (binary is smaller but may not be portable between machines)\n",
    "USE_BINARY_FOR_SEISMOGRAMS      = .false.\n",
    "\n",
    "# output seismograms in Seismic Unix format (binary with 240-byte-headers)\n",
    "SU_FORMAT                       = .false.\n",
    "\n",
    "# output seismograms in ASDF (requires asdf-library)\n",
    "ASDF_FORMAT                     = .false.\n",
    "\n",
    "# output seismograms in HDF5 (requires hdf5-library and WRITE_SEISMOGRAMS_BY_MAIN)\n",
    "HDF5_FORMAT                     = .false.\n",
    "\n",
    "# decide if main process writes all the seismograms or if all processes do it in parallel\n",
    "WRITE_SEISMOGRAMS_BY_MAIN       = .false.\n",
    "\n",
    "# save all seismograms in one large combined file instead of one file per seismogram\n",
    "# to avoid overloading shared non-local file systems such as LUSTRE or GPFS for instance\n",
    "SAVE_ALL_SEISMOS_IN_ONE_FILE    = .false.\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "# Run modes\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# Simultaneous runs\n",
    "NUMBER_OF_SIMULTANEOUS_RUNS     = 1\n",
    "\n",
    "# if we perform simultaneous runs in parallel, if only the source and receivers vary between these runs\n",
    "# but not the mesh nor the model (velocity and density) then we can also read the mesh and model files\n",
    "# from a single run in the beginning and broadcast them to all the others; for a large number of simultaneous\n",
    "# runs for instance when solving inverse problems iteratively this can DRASTICALLY reduce I/Os to disk\n",
    "BROADCAST_SAME_MESH_AND_MODEL   = .true.\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# set to true to use GPUs\n",
    "GPU_MODE                        = .false.\n",
    "\"\"\")\n",
    "print(f\"Created complete Par_file at {complete_par_file}\")\n",
    "\n",
    "# Create a custom Mesh_Par_file to ensure it has the necessary parameters\n",
    "mesh_par_file = os.path.join(specfem_dir, \"DATA/Mesh_Par_file\")\n",
    "with open(mesh_par_file, 'w') as f:\n",
    "    f.write(\"\"\"#-----------------------------------------------------------\n",
    "#\n",
    "# Meshing input parameters\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# coordinates of mesh block in latitude/longitude and depth in km\n",
    "LATITUDE_MIN                    = 0.0\n",
    "LATITUDE_MAX                    = 2000.0\n",
    "LONGITUDE_MIN                   = 0.0\n",
    "LONGITUDE_MAX                   = 2000.0\n",
    "DEPTH_MIN                       = 0.0\n",
    "DEPTH_MAX                       = 2000.0\n",
    "\n",
    "# file that contains the interfaces of the model / mesh\n",
    "INTERFACES_FILE                 = interfaces.dat\n",
    "\n",
    "# file that contains the cavity\n",
    "CAVITY_FILE                     = no_cavity.dat\n",
    "\n",
    "# number of elements at the surface along edges of the mesh at the surface\n",
    "# (must be 8 * multiple of NPROC below if mesh is not regular and contains mesh doublings)\n",
    "# (must be multiple of NPROC below if mesh is regular)\n",
    "NEX_XI                          = 40\n",
    "NEX_ETA                         = 40\n",
    "\n",
    "# number of MPI processors along xi and eta (can be different)\n",
    "NPROC_XI                        = 2\n",
    "NPROC_ETA                       = 2\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "# Doubling layers\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# Regular/irregular mesh\n",
    "USE_REGULAR_MESH                = .true.\n",
    "# Only for irregular meshes, number of doubling layers and their position\n",
    "NDOUBLINGS                      = 0\n",
    "# NZ_DOUBLING_1 is the parameter to set up if there is only one doubling layer\n",
    "# (more doubling entries can be added if needed to match NDOUBLINGS value)\n",
    "NZ_DOUBLING_1                   = 0\n",
    "NZ_DOUBLING_2                   = 0\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "# Visualization\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# create mesh files for visualisation or further checking\n",
    "CREATE_ABAQUS_FILES             = .false.\n",
    "CREATE_DX_FILES                 = .false.\n",
    "CREATE_VTK_FILES                = .true.\n",
    "\n",
    "# path to store the databases files\n",
    "LOCAL_PATH                      = ./DATABASES_MPI\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "# Domain materials\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# number of materials\n",
    "NMATERIALS                      = 1\n",
    "# define the different materials in the model as:\n",
    "# #material_id  #rho  #vp  #vs  #Q_Kappa  #Q_mu  #anisotropy_flag  #domain_id\n",
    "1 2700.0 3500.0 2000.0 9999.0 9999.0 0 2\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "# Domain regions\n",
    "#\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "# number of regions\n",
    "NREGIONS                        = 1\n",
    "# define the different regions of the model as :\n",
    "#NEX_XI_BEGIN  #NEX_XI_END  #NEX_ETA_BEGIN  #NEX_ETA_END  #NZ_BEGIN #NZ_END  #material_id\n",
    "1 40 1 40 1 40 1\n",
    "\"\"\")\n",
    "print(f\"Created custom Mesh_Par_file at {mesh_par_file}\")\n",
    "\n",
    "# Create meshfem3D_files directory if it doesn't exist\n",
    "meshfem3d_files_dir = os.path.join(specfem_dir, \"DATA/meshfem3D_files\")\n",
    "os.makedirs(meshfem3d_files_dir, exist_ok=True)\n",
    "\n",
    "# Copy SOURCE and STATIONS files\n",
    "shutil.copy(os.path.join(output_dir, \"SOURCE\"), os.path.join(specfem_dir, \"DATA/SOURCE\"))\n",
    "shutil.copy(os.path.join(output_dir, \"STATIONS\"), os.path.join(specfem_dir, \"DATA/STATIONS\"))\n",
    "print(\"Copied SOURCE and STATIONS files to SPECFEM3D DATA directory\")\n",
    "\n",
    "# Create interfaces.dat file in meshfem3D_files directory\n",
    "interfaces_file = os.path.join(meshfem3d_files_dir, \"interfaces.dat\")\n",
    "with open(interfaces_file, 'w') as f:\n",
    "    f.write(\"\"\"# number of interfaces\n",
    "1\n",
    "# for each interface below, we give the number of points in xi and eta directions\n",
    "2 2\n",
    "# and then x,y,z for all these points (xi and eta being the first and second directions respectively)\n",
    "0.0 0.0 0.0\n",
    "2000.0 0.0 0.0\n",
    "0.0 2000.0 0.0\n",
    "2000.0 2000.0 0.0\n",
    "\"\"\")\n",
    "\n",
    "# Create no_cavity.dat file in meshfem3D_files directory\n",
    "cavity_file = os.path.join(meshfem3d_files_dir, \"no_cavity.dat\")\n",
    "with open(cavity_file, 'w') as f:\n",
    "    f.write(\"# No cavity\")\n",
    "\n",
    "print(\"Created interfaces.dat and no_cavity.dat files\")\n",
    "\n",
    "# Create DATABASES_MPI directory if it doesn't exist\n",
    "databases_dir = os.path.join(specfem_dir, \"OUTPUT_FILES/DATABASES_MPI\")\n",
    "os.makedirs(databases_dir, exist_ok=True)\n",
    "print(\"Created DATABASES_MPI directory\")\n",
    "\n",
    "# Now run the mesher directly using the system command\n",
    "print(\"Running xmeshfem3D directly...\")\n",
    "# Save current directory\n",
    "current_dir = os.getcwd()\n",
    "try:\n",
    "    # Change to SPECFEM directory\n",
    "    os.chdir(specfem_dir)\n",
    "    # Run the mesher\n",
    "    os.system(f\"mpirun -np 4 ./bin/xmeshfem3D\")\n",
    "    # Check if it worked\n",
    "    if os.path.exists(os.path.join(specfem_dir, \"OUTPUT_FILES/DATABASES_MPI/proc000000_reg1_mesh.vtk\")):\n",
    "        print(\"Meshing completed successfully.\")\n",
    "        mesh_success = True\n",
    "    else:\n",
    "        print(\"Meshing failed - no mesh files found.\")\n",
    "        mesh_success = False\n",
    "finally:\n",
    "    # Return to original directory\n",
    "    os.chdir(current_dir)\n",
    "\n",
    "# If meshing was successful, try to run the partitioner\n",
    "if mesh_success:\n",
    "    print(\"\\nRunning the partitioner...\")\n",
    "    try:\n",
    "        # Change to SPECFEM directory\n",
    "        os.chdir(specfem_dir)\n",
    "        # Run the partitioner\n",
    "        os.system(f\"mpirun -np 4 ./bin/xdecompose_mesh\")\n",
    "        # Run the solver\n",
    "        print(\"\\nRunning the solver...\")\n",
    "        os.system(f\"mpirun -np 4 ./bin/xspecfem3D\")\n",
    "    finally:\n",
    "        # Return to original directory\n",
    "        os.chdir(current_dir)\n",
    "    \n",
    "    # Check if seismograms were created\n",
    "    seismogram_files = list(Path(specfem_dir).glob(\"OUTPUT_FILES/*.semd\"))\n",
    "    if seismogram_files:\n",
    "        print(f\"Solver completed successfully. Created {len(seismogram_files)} seismogram files.\")\n",
    "        # Copy seismogram files to output directory\n",
    "        for file in seismogram_files:\n",
    "            shutil.copy(file, output_dir)\n",
    "        print(f\"Copied seismogram files to {output_dir}\")\n",
    "    else:\n",
    "        print(\"Solver did not produce any seismogram files.\")\n",
    "else:\n",
    "    print(\"Skipping partitioner and solver since meshing failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running partitioner...\n",
      "2025-03-21 21:56:27 - src.simulation.specfem_runner - INFO - Running xdecompose_mesh...\n",
      "Running xdecompose_mesh...\n",
      "Executing: mpirun -np 4 ./bin/xdecompose_mesh\n",
      "2025-03-21 21:56:27 - src.simulation.specfem_runner - INFO - Partitioning completed successfully\n",
      "Partitioning completed successfully\n",
      "Partitioning completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Run the partitioner\n",
    "print(\"Running partitioner...\")\n",
    "success = sim.run_partitioner()\n",
    "if not success:\n",
    "    print(\"Partitioning failed!\")\n",
    "else:\n",
    "    print(\"Partitioning completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and Visualize the Outputs\n",
    "\n",
    "Now that the simulation has completed, let's load and visualize the output seismograms. First, we'll define a function to load the seismogram files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load seismogram files\n",
    "def load_seismograms(output_dir, component='X'):\n",
    "    \"\"\"Load seismograms from SPECFEM3D output directory.\n",
    "    \n",
    "    Args:\n",
    "        output_dir (str): Path to output directory\n",
    "        component (str): Component to load (X, Y, or Z)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (times, data) where data has shape (n_stations, n_time_steps)\n",
    "               or empty arrays if no files found\n",
    "    \"\"\"\n",
    "    # Find all seismogram files for the component\n",
    "    seismo_files = sorted(Path(output_dir).glob(f\"*.{component}.semd\"))\n",
    "    \n",
    "    if not seismo_files:\n",
    "        print(f\"No {component}-component seismograms found in {output_dir}\")\n",
    "        # Return empty arrays instead of None\n",
    "        return np.array([]), np.array([]).reshape(0, 0)\n",
    "    \n",
    "    # Load the first file to get time samples\n",
    "    first_data = np.loadtxt(seismo_files[0])\n",
    "    times = first_data[:, 0]\n",
    "    n_time_steps = len(times)\n",
    "    n_stations = len(seismo_files)\n",
    "    \n",
    "    # Initialize data array\n",
    "    data = np.zeros((n_stations, n_time_steps))\n",
    "    data[0, :] = first_data[:, 1]  # Add the first trace\n",
    "    \n",
    "    # Load remaining traces\n",
    "    for i, file_path in enumerate(seismo_files[1:], start=1):\n",
    "        trace_data = np.loadtxt(file_path)\n",
    "        data[i, :] = trace_data[:, 1]\n",
    "            \n",
    "    return times, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No X-component seismograms found in /home/masa/ml_interpolation/data/synthetic/raw/simulation1\n",
      "No Y-component seismograms found in /home/masa/ml_interpolation/data/synthetic/raw/simulation1\n",
      "No Z-component seismograms found in /home/masa/ml_interpolation/data/synthetic/raw/simulation1\n",
      "No X-component data was loaded.\n",
      "No Y-component data was loaded.\n",
      "No Z-component data was loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load seismograms for all components\n",
    "times_x, data_x = load_seismograms(output_dir, component='X')\n",
    "times_y, data_y = load_seismograms(output_dir, component='Y')\n",
    "times_z, data_z = load_seismograms(output_dir, component='Z')\n",
    "\n",
    "# Check if data was loaded successfully\n",
    "if data_x.size > 0:\n",
    "    print(f\"Loaded {data_x.shape[0]} X-component seismograms, each with {data_x.shape[1]} time steps.\")\n",
    "else:\n",
    "    print(\"No X-component data was loaded.\")\n",
    "\n",
    "if data_y.size > 0:\n",
    "    print(f\"Loaded {data_y.shape[0]} Y-component seismograms, each with {data_y.shape[1]} time steps.\")\n",
    "else:\n",
    "    print(\"No Y-component data was loaded.\")\n",
    "\n",
    "if data_z.size > 0:\n",
    "    print(f\"Loaded {data_z.shape[0]} Z-component seismograms, each with {data_z.shape[1]} time steps.\")\n",
    "else:\n",
    "    print(\"No Z-component data was loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available to plot traces.\n"
     ]
    }
   ],
   "source": [
    "# Plot a single trace if data is available\n",
    "if data_x.size > 0 and times_x.size > 0:\n",
    "    station_idx = min(50, data_x.shape[0]-1)  # Middle station or last available\n",
    "    plot_seismic_trace(times_x, data_x[station_idx], \n",
    "                      title=f\"X-component - Station {station_idx+1}\",\n",
    "                      xlabel=\"Time (s)\", ylabel=\"Displacement\")\n",
    "else:\n",
    "    print(\"No data available to plot traces.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available to plot gather.\n"
     ]
    }
   ],
   "source": [
    "# Plot the gather (all traces) for X-component if data is available\n",
    "if data_x.size > 0:\n",
    "    plot_seismic_gather(data_x, title=\"X-component Gather\", \n",
    "                      xlabel=\"Time Sample\", ylabel=\"Station\")\n",
    "else:\n",
    "    print(\"No data available to plot gather.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data\n",
    "\n",
    "Now that we have loaded and visualized the seismograms, let's save them in a structured format for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No X-component data to save\n",
      "No Y-component data to save\n",
      "No Z-component data to save\n",
      "Saved station information to ../data/synthetic/processed/simulation1/stations.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a processed data directory\n",
    "processed_dir = Path(\"../data/synthetic/processed/simulation1\")\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save data as numpy arrays if data is available\n",
    "if data_x.size > 0 and times_x.size > 0:\n",
    "    np.save(processed_dir / \"times.npy\", times_x)\n",
    "    np.save(processed_dir / \"data_x.npy\", data_x)\n",
    "    print(f\"Saved X-component data to {processed_dir}\")\n",
    "else:\n",
    "    print(\"No X-component data to save\")\n",
    "\n",
    "if data_y.size > 0:\n",
    "    np.save(processed_dir / \"data_y.npy\", data_y)\n",
    "    print(f\"Saved Y-component data to {processed_dir}\")\n",
    "else:\n",
    "    print(\"No Y-component data to save\")\n",
    "\n",
    "if data_z.size > 0:\n",
    "    np.save(processed_dir / \"data_z.npy\", data_z)\n",
    "    print(f\"Saved Z-component data to {processed_dir}\")\n",
    "else:\n",
    "    print(\"No Z-component data to save\")\n",
    "\n",
    "# Save station information\n",
    "station_df = pd.DataFrame(stations_list)\n",
    "station_df.to_csv(processed_dir / \"stations.csv\", index=False)\n",
    "print(f\"Saved station information to {processed_dir}/stations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
